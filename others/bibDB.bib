% Encoding: UTF-8

@Article{PENGHAO2018,
  author   = {PENG HAO, (Member, IEEE), XIANBIN WANG, (Fellow, IEEE),AND WEIMING SHEN, (Fellow, IEEE)},
  title    = {A Collaborative PHY-Aided Technique For End-to-End IoT Device Authentication},
  journal  = {IEEE},
  year     = {2018},
  volume   = {6},
  pages    = {15},
  month    = jul,
  abstract = {Nowadays, Internet of Things (IoT) devices are rapidly proliferating to support a vast numberof end-to-end (E2E) services and applications, which require reliable device authentication for E2E data security. However, most low-cost IoT end devices with limited computing resources have difficulties in executing the increasingly complicated cryptographic security protocols, resulting in increased vulnerability of the virtual authentication credentials to malicious cryptanalysis. An attacker possessing compromised credentials could be deemed legitimate by the conventional cryptography-based authentication. Although
inherently robust to upper-layer unauthorized cryptanalysis, the device-to-device physical-layer (PHY) authentication is practically difficult to be applied to the E2E IoT scenario and to be integrated with the existing, well-established cryptography primitives without any conflict. This paper proposes an enhanced E2E IoT device authentication that achieves seamless integration of PHY security into traditional asymmetric
cryptography-based authentication schemes. Exploiting the collaboration of several intermediate nodes (e.g., edge gateway, access point, and full-function device), multiple radio-frequency features of an IoT device can be estimated, quantized, and used in the proposed PHY identity-based cryptography for key protection. A closed-form expression of the generated PHY entropy is derived for measuring the security enhancement. The evaluation results of our cross-layer authentication demonstrate an elevated resistance to various computation-based impersonation attacks. Furthermore, the proposed method does not impose any extra implementation overhead on resource-constrained IoT devices.},
  file     = {:C\:/project/FYP done/RPs/Cryptography/A Collaborative PHY-Aided Technique For.pdf:PDF},
  keywords = {Device authentication, Internet of Things, physical layer security, collaborative security, radio-frequency fingerprinting, cross-layer security.},
  url      = {file:///C:/Users/khiyra009gmail.com/Downloads/Cryptography/Cryptography/A%20Collaborative%20PHY-Aided%20Technique%20For.pdf},
}

@Article{PINGYUANZHANG2018,
  author   = {PINGYUAN ZHANG, HAN JIANG, ZHIHUA ZHENG, PEICHU HU, AND QIULIANG XU},
  title    = {A new qost-quantum blind signature from lattice assumptions},
  journal  = {IEEE},
  year     = {2018},
  volume   = {6},
  pages    = {8},
  month    = may,
  abstract = {At present, several post-quantum cryptosystems have been proposed, and lattice-based cryptographyis the main candidate. Especially in the direction of digital signatures, there are now many practical lattice-based signature schemes. However, there exist few lattice-based signatures with special property such as blind signature. Blind signature was introduced by Chaum for creating untraceable payment system. Then, it is widely used in e-cash and voting, especially in the revolutionary digital cash system based on blockchain. In our paper, we present a method to construct a post-quantum blind signature based on lattice assumptions, and we proved that any existential forger against the security of the resulting scheme can solve the SISq,n,m,β, problem for β = eO(dn). Our main technique is the rejection sampling theory. The expected number of times needed to output a blind signature is at most e2 under aborting, and our new scheme has much smaller signature size than those of all the previously proposed blind signature schemes over lattices.},
  file     = {:C\:/project/FYP done/RPs/Cryptography/A New Post-Quantum Blind Signature.pdf:PDF},
  keywords = {Post-quantum cryptography, blind signatures, lattices, provable security, digital cash system.},
  url      = {file:///C:/Users/khiyra009gmail.com/Downloads/Cryptography/Cryptography/A%20New%20Post-Quantum%20Blind%20Signature.pdf},
}

@Article{KHASAWNEH2017,
  author   = {MAHMOUD KHASAWNEH AND ANJALI AGARWAL},
  title    = {A Secure and Efficient Authentication Mechanism Applied to Cognitive Radio Networks},
  journal  = {IEEE},
  year     = {2017},
  volume   = {5},
  pages    = {12},
  month    = jul,
  abstract = {Cognitive radio (CR) has been introduced to accommodate the steady increment in the spectrum demand. Wireless security in CR network (CRN) is a challenging technical area due to the dynamic and unique characteristics of CRNs. As a cognitive node can dynamically join or leave the spectrum, providing secure communication becomes problematic and requires more investigation. Authentication is a primary security property in wireless networks, wherein the identity of a cognitive node is verified before providing access to available resources. In this paper, a two-level authentication scheme for communication in a CRN is proposed. Before joining the network, a CR node is validated by obtaining security credentials from an authorized point. The proposed scheme relies on public- and symmetric-key cryptography, instead of using a digital signature-based approach. It encrypts data between the communicating nodes in order to improve network security in terms of resource availability and accessibility. This mitigates attacks such as reflection attack, denial of service attack, and man-in-the-middle attack. The scheme has been evaluated and verified in terms of security functionality, its correctness, and the performance, which shows less computation and communication requirements.},
  file     = {:C\:/project/FYP done/RPs/Cryptography/A Secure and Efficient Authentication Mechanism.pdf:PDF},
  keywords = {Authentication, cognitive radio, security, symmetric key, cryptography.},
  url      = {file:///C:/Users/khiyra009gmail.com/Downloads/Cryptography/Cryptography/A%20Secure%20and%20Efficient%20Authentication%20Mechanism.pdf},
}

@Article{HADEALABDULAZIZALHAMID2017,
  author   = {HADEAL ABDULAZIZ AL HAMID, SK MD MIZANUR RAHMAN, (Member, IEEE), M. SHAMIM HOSSAIN, (Senior Member, IEEE), AHMAD ALMOGREN, (Member, IEEE), AND ATIF ALAMRI},
  title    = {A security model for preserving the privacy of medical big data in a healthcare cloud using a fog computing facility with pairing-based cryptography},
  journal  = {IEEE},
  year     = {2017},
  volume   = {5},
  pages    = {16},
  month    = sep,
  abstract = {Nowadays, telemedicine is an emerging healthcare service where the healthcare professionals can diagnose, evaluate, and treat a patient using telecommunication technology. To diagnose and evaluate a patient, the healthcare professionals need to access the electronic medical record (EMR) of the patient, which might contain huge multimedia big data including X-rays, ultrasounds, CT scans, and MRI reports. For efficient access and supporting mobility for both the healthcare professionals as well as the patients, the EMR needs to be kept in big data storage in the healthcare cloud. In spite of the popularity of the healthcare cloud, it faces different security issues; for instance, data theft attacks are considered to be one of the most serious security breaches of healthcare data in the cloud. In this paper, the main focus has been given to secure healthcare private data in the cloud using a fog computing facility. To this end, a tri-party one-round authenticated key agreement protocol has been proposed based on the bilinear pairing cryptography that can generate a session key among the participants and communicate among them securely. Finally, the private healthcare data are accessed and stored securely by implementing a decoy technique.},
  file     = {:C\:/project/FYP done/RPs/Cryptography/A Security Model for Preserving the Privacy of healthcare.pdf:PDF},
  keywords = {Key management, security and privacy, medical big data, fog computing, pairing-based cryptography, decoy technique.},
  url      = {file:///C:/Users/khiyra009gmail.com/Downloads/Cryptography/Cryptography/A%20Security%20Model%20for%20Preserving%20the%20Privacy%20of%20healthcare.pdf},
}

@Article{Zhou2016,
  author   = {Xinyi Zhou, Wei Gong,WenLong Fu, LianJing Jin},
  title    = {An improved method for LSB based color image steganography combined with cryptography},
  journal  = {IEEE},
  year     = {2016},
  pages    = {4},
  month    = jun,
  abstract = {In this paper, an improved LSB information hiding algorithm of color image using secret key is be proposed,combining information hiding and cryptography, increasing the human eye visual features, and the identity authentication based on digital signature and encryption technology to improve the security of information hiding. Finally through the experiment and the comparison of the peak signal-to-noise ratio (PSNR) and safety, the improved LSB image steganography algorithm using the encryption technology is better than general LSB image steganographic method with better security and higher PSNR. },
  file     = {:C\:/project/FYP done/RPs/Cryptography/An Improved Method for LSB Based Color Image.pdf:PDF},
  keywords = {image hiding; information security; secret key; LSB; encryption; },
  url      = {file:///C:/Users/khiyra009gmail.com/Downloads/Cryptography/Cryptography/An%20Improved%20Method%20for%20LSB%20Based%20Color%20Image.pdf},
}

@Article{ZHINIANG2017,
  author   = {ZHINIANG PENG AND SHAOHUA TANG, (Member, IEEE)},
  title    = {Circulant Rainbow: A New Rainbow Variant With Shorter Private Key and Faster Signature Generation},
  journal  = {IEEE},
  year     = {2017},
  volume   = {5},
  pages    = {10},
  month    = jun,
  abstract = {Rainbow is one of the most important signature schemes in multivariate public key cryptography. It enjoys a strong security guarantee and is a promising signature scheme in Post-Quantum Cryptography. However, it suffers from large key size. In this paper, we propose Circulant Rainbow with shorter private key and higher signing efficiency. In Circulant Rainbow, we introduce rotating relations into parts of Rainbow private key to speed up the signing procedure and reduce the private key size. We carefully choose security parameters so that our Circulant Rainbow is secure against all known attacks. In our experiment, Circulant Rainbow is about three times faster than original Rainbow and it can reduce the private key size by about 45%. We also make a comparison of Circulant Rainbow with some traditional signature schemes, the results show that Circulant Rainbow is a promising candidate in Post-Quantum Cryptography.},
  file     = {:C\:/project/FYP done/RPs/Cryptography/Circulant Rainbow A New Rainbow Variant.pdf:PDF},
  keywords = {MPKC, Rainbow signature scheme, Post-Quantum Cryptography, AVX2},
  url      = {file:///C:/Users/khiyra009gmail.com/Downloads/Cryptography/Cryptography/Circulant%20Rainbow%20A%20New%20Rainbow%20Variant.pdf},
}

@Article{ZarkoStanisavljevic2014,
  author   = {Zarko Stanisavljevic, Jelena Stanisavljevic, Pavle Vuletic, and Zoran Jovanovic},
  title    = {COALA-System for Visual Representation of Cryptography Algorithms},
  journal  = {IEEE},
  year     = {2014},
  volume   = {7},
  number   = {2},
  pages    = {13},
  month    = jun,
  abstract = {Educational software systems have an increasingly significant presence in engineering sciences. They aim to improve students’ attitudes and knowledge acquisition typically through visual representation and simulation of complex algorithms and mechanisms or hardware systems that are often not available to the educational institutions. This paper presents a novel software, system for CryptOgraphic ALgorithm visuAl representation (COALA), which was developed to support a Data Security course at the School of Electrical Engineering, University of Belgrade. The system allows users to follow the execution of several complex algorithms (DES, AES, RSA, and Diffie-Hellman) on real world examples in a step by step detailed view with the possibility of forward and backward navigation. Benefits of the COALA system for students are observed through the increase of the percentage of students who passed the exam and the average grade on the exams during one school year.},
  file     = {:C\:/project/FYP done/RPs/Cryptography/Cryptography Algorithms.pdf:PDF},
  keywords = {AES, algorithm visualization, cryptographic algorithms, data security, DES, Diffie-Hellman, RSA, security education},
  url      = {file:///C:/Users/khiyra009gmail.com/Downloads/Cryptography/Cryptography/Cryptography%20Algorithms.pdf},
}

@Article{FagenLi2016,
  author   = {Fagen Li, Member, IEEE, and Jiaojiao Hong},
  title    = {Efficient Certificateless Access Control for Wireless Body Area Networks},
  journal  = {IEEE},
  year     = {2016},
  volume   = {16},
  number   = {13},
  pages    = {8},
  month    = jul,
  abstract = {Wireless body area networks (WBANs) are expected to act as an important role in monitoring the health information and creating a highly reliable ubiquitous healthcare system. Since the data collected by the WBANs are used to diagnose and treat, only authorized users can access these data. Therefore, it is important to design an access control scheme that can authorize, authenticate, and revoke a user to access the WBANs. In this paper, we first give an efficient certificateless signcryption scheme and then design an access control scheme for the WBANs using the given signcryption. Our scheme achieves confidentiality, integrity, authentication, non-repudiation, public verifiability, and ciphertext authenticity. Compared with existing three access control schemes using signcryption, our scheme has the least computational cost and energy consumption for the controller. In addition, our scheme has neither key escrow nor public key certificates, since it is based on certificateless cryptography},
  file     = {:C\:/project/FYP done/RPs/Cryptography/Efficient Certificateless Access Control.pdf:PDF},
  keywords = {Wireless body area networks, security, access control, signcryption, certificateless cryptography.},
  url      = {file:///C:/Users/khiyra009gmail.com/Downloads/Cryptography/Cryptography/Efficient%20Certificateless%20Access%20Control.pdf},
}

@Article{SHENGDING2018,
  author   = {SHENG DING , CHEN LI, AND HUI LI},
  title    = {A Novel Efficient Pairing-Free CP-ABE Based on Elliptic Curve Cryptography for IoT},
  journal  = {IEEE},
  year     = {2018},
  volume   = {6},
  pages    = {10},
  month    = may,
  abstract = {Ciphertext-policy attribute-based encryption (CP-ABE) is a promising cryptographic technique that integrates data encryption with access control for ensuring data security in IoT systems. However, the efficiency problem of CP-ABE is still a bottleneck limiting its development and application. A widespread consensus is that the computation overhead of bilinear pairing is excessive in the practical application of ABE, especially for the devices or the processors with limited computational resources and power supply. In this paper, we proposed a novel pairing-free data access control scheme based on CP-ABE using elliptic curve cryptography, abbreviated PF-CP-ABE. We replace complicated bilinear pairing with simple scalar multiplication on elliptic curves, thereby reducing the overall computation overhead. And we designed a new way of key distribution that it can directly revoke a user or an attribute without updating other users’ keys during the attribute revocation phase. Besides, our scheme use linear secret sharing scheme access structure to enhance the expressiveness of the access policy. The security and performance analysis show that our scheme significantly improved the overall efficiency as well as ensured the security.},
  file     = {:C\:/project/FYP done/RPs/Cryptography/Elliptic Curve Cryptography for iot.pdf:PDF},
  keywords = {Access control, internet of things, CP-ABE, elliptic curve, pairing-free.},
  url      = {file:///C:/Users/khiyra009gmail.com/Downloads/Cryptography/Cryptography/Elliptic%20Curve%20Cryptography%20for%20iot.pdf},
}

@Article{SHUMINGQIU2017,
  author   = {SHUMING QIU, GUOAI XU, HASEEB AHMAD, AND LICHENG WANG},
  title    = {A Robust Mutual Authentication Scheme Based on Elliptic Curve Cryptography for Telecare Medical Information Systems},
  journal  = {IEEE},
  year     = {2017},
  volume   = {6},
  pages    = {12},
  month    = dec,
  abstract = {The telecare medical information systems (TMISs) provide the convenience to the patients/users to be served at home. Along with such ease, it is essential to preserve the privacy and to provide
the security to the patients/users in TMIS. Often, authentication protocols are adopted to guarantee privacy and secure interaction between the patients/users and remote server. Recently, Chaudhry et al. pointed out
that Islam et al.’s scheme based on smart card is prone to user impersonation and server impersonation attacks. Chaudhry et al. later presented an enhanced scheme based on elliptic curve cryptography to remedy
the weaknesses of Islam et al.’s scheme. Unfortunately, we find some important limitations in both schemes. We remark that their scheme is prone to off-line password guessing attack, user/server impersonation attack,
and man-in-middle attack. To overcome these limitations, we present an improved authentication scheme,keeping apart the threats encountered in the design of Chaudhry et al.’s scheme. Moreover, the presented
scheme can also resist all known attacks. We prove the security of the proposed scheme with the help of widespread Burrows–Abadi–Needham logic. A brief comparison with the previous works provides that the
presented protocol is more efficient and more secure than other related schemes.},
  file     = {:C\:/project/FYP done/RPs/Cryptography/Elliptic Curve Cryptography for Telecare syatem.pdf:PDF},
  keywords = {Telecare medicine information systems, elliptic curve cryptography, smart card, off-line password guessing attack, authentication, BAN-logic},
  url      = {file:///C:/Users/khiyra009gmail.com/Downloads/Cryptography/Cryptography/Elliptic%20Curve%20Cryptography%20for%20Telecare%20syatem.pdf},
}

@Article{CARLOSA.LARA-NINO2016,
  author   = {CARLOS A. LARA-NINO, ARTURO DIAZ-PEREZ, AND MIGUEL MORALES-SANDOVAL},
  title    = {Elliptic Curve Lightweight Cryptography: a Survey},
  journal  = {IEEE},
  year     = {2016},
  volume   = {4},
  pages    = {37},
  abstract = {Since it was invented in 1986, Elliptic Curve Cryptography (ECC) has been studied widely in industry and academy from different perspectives. Some of these aspects include mathematical foundations, protocol design, curve generation, security proofs, point representation, algorithms for inherent arithmetic in the underlying algebraic structures, implementation strategies in both software and hardware, attack models,
among others. The main advantage of ECC is that shorter keys (less memory requirements and faster field arithmetic operations) can be used if compared to other cryptosystems, which has made it the ideal choice for
implementing public key cryptography in resource constrained devices, as the ones found in the envisioned applications of the Internet of Things (IoT), e.g. wireless sensors. In this application domain, lightweight
cryptography has emerged as the one required because of the scarce computing resources and the limited energy in devices. In this paper we present a survey of ECC in the context of lightweight cryptography. The
aim of this work is to identify the criteria that make an ECC-based system lightweight and a viable solution for using in practical constrained applications. Representative works are systematically revised to determine
the key aspects considered in ECC designs for lightweight realizations. As a result, this paper defines, for the first time, the concept and requirements for Elliptic Curve Lightweight Cryptography (ECLC).},
  file     = {:C\:/project/FYP done/RPs/Cryptography/Elliptic Curve Lightweight Cryptography.pdf:PDF},
  keywords = {Cryptography, Elliptic Curve, Lightweight, Survey},
  url      = {file:///C:/Users/khiyra009gmail.com/Downloads/Cryptography/Cryptography/Elliptic%20Curve%20Lightweight%20Cryptography.pdf},
}

@Article{TANPINGZHOU2018,
  author   = {TANPING ZHOU , XIAOYUAN YANG, LONGFEI LIU, WEI ZHANG, AND NINGBO LI},
  title    = {Faster Bootstrapping With Multiple Addends},
  journal  = {IEEE},
  year     = {2018},
  volume   = {6},
  pages    = {9},
  month    = aug,
  abstract = {As an important cryptographic primitive in cloud computing and outsourced computing, fully
homomorphic encryption (FHE) is an animated area in modern cryptography. However, the efficiency of
FHE has been a bottleneck that impeding its application. According to Gentry’s blueprint, bootstrapping,
which is used to control the noise propagation in ciphertexts, is the most important process in FHE.
However, bootstrapping is also the most expensive process that affects the scheme’s efficiency. This paper
has made three improvements to accelerate the bootstrapping. Firstly, as hundreds of serial homomorphic
additions take most of the time of bootstrapping, we constructed the logical expression using truth table
to reduce the amount of serial homomorphic additions by two-thirds and thus proposed an efficient FHE
scheme with bootstrapping within 10 ms. Secondly, the most expensive parts in our bootstrapping, enhanced
homomorphic constant multiplication and homomorphic addition, can be implemented in parallel, which
may accelerate the bootstrapping. At last, we proposed a set of more efficient combinations of parameters.
Analysis shows that our scheme’s security level is 128 bits and the correctness is improved compared with
CGGI16 scheme in ASIACRYPT 2016. Experiments show that the running time of bootstrapping in this
paper is within 10 ms, which is only 52% of CGGI16, and is less than CGGI17 in ASIACRYPT 2017.},
  file     = {:C\:/project/FYP done/RPs/Cryptography/Faster Bootstrapping With Multiple Addends.pdf:PDF},
  keywords = {Data security, cryptography, public key, fully homomorphic encryption, bootstrapping process, accumulator, TFHE.},
  url      = {file:///C:/Users/khiyra009gmail.com/Downloads/Cryptography/Cryptography/Faster%20Bootstrapping%20With%20Multiple%20Addends.pdf},
}

@Article{HouzhenWang2016,
  author   = {Houzhen Wang, Huanguo Zhang, Shaowu Mao, Wanqing Wu, and Liqiang Zhang},
  title    = {New Public-Key Cryptosystem Based on the Morphism of Polynomials Problem},
  journal  = {IEEE},
  year     = {2016},
  volume   = {21},
  number   = {3},
  pages    = {10},
  month    = jun,
  abstract = {During the last two decades, there has been intensive and fast development in Multivariate Public Key
Cryptography (MPKC), which is considered to be an important candidate for post-quantum cryptography. However,
it is universally regarded as a difficult task, as in the Knapsack cryptosystems, to design a secure MPKC scheme
(especially an encryption scheme) employing the existing trapdoor construction. In this paper, we propose a
new key-exchange scheme and an MPKC scheme based on the Morphism of Polynomials (MP) problem. The
security of the proposed schemes is provably reducible to the conjectured intractability of a new difficult problem,
namely the Decisional Multivariate Diffie-Hellman (DMDH) problem derived from the MP problem. The proposed
key agreement is one of several non-number-theory-based protocols, and is a candidate for use in the post-quantum
era. More importantly, by slightly modifying the protocol, we offer an original approach to designing a secure MPKC
scheme. Furthermore, the proposed encryption scheme achieves a good tradeoff between security and efficiency,
and seems competitive with traditional MPKC schemes.},
  file     = {:Cryptography/New Public-Key Cryptosystem Based on the Morphism of.pdf:PDF},
  keywords = {: public key cryptosystem; key exchange; Multivariate Public Key Cryptography (MPKC); Morphism of Polynomials (MP) problem},
  url      = {file:///C:/Users/khiyra009gmail.com/Downloads/Cryptography/Cryptography/New%20Public-Key%20Cryptosystem%20Based%20on%20the%20Morphism%20of.pdf},
}

@Article{LEHLOGONOLOP.I.LEDWABA2018,
  author   = {LEHLOGONOLO P. I. LEDWABA , GERHARD P. HANCKE, (Senior Member, IEEE), HEIN S. VENTER4, (Member, IEEE), AND SHERRIN J. ISAAC1, (Member, IEEE)},
  title    = {Performance Costs of Software Cryptography in Securing New-Generation Internet of Energy Endpoint Devices},
  journal  = {IEEE},
  year     = {2018},
  volume   = {6},
  pages    = {21},
  month    = dec,
  abstract = { In past years, cryptography has been considered a difficult task to achieve on sensor nodes for
the Internet of Energy (IoE) owing to the resource-constrained nature of 8- and 16-bit microcontroller units
(MCUs). Previous attempts at implementing cryptographic services on wireless sensor nodes have resulted
in high power consumptions, long operating times, and the depletion of memory resources. Over the last
decade, however, processors for the IoT and IoE have improved; with increased operating power and memory
resources, longer data bus widths and low-power consumption. With the improvements made to processors
suitable for building IoT devices, the question remains whether endpoint nodes should still be considered
capable of only supporting the most lightweight of cryptographic mechanisms. We evaluate the capabilities
of a device family (Cortex-M series processors) commonly found in programmable logic controllers
to implement standard, verified software cryptographic libraries in terms of execution times, memory
occupation, and power consumption in order to determine their adequacy for use in smart grid applications.
It was seen that the MCUs were easily capable of running standard cryptographic algorithms. However,
the use of public key cryptography may still require the inclusion of a hardware crypto accelerator or the use
of a secure MCU implementing public key cryptography; as the relatively long execution times seen during
the operation of ECDSA, for example, could be intolerable within a real time IoE application.},
  file     = {:Cryptography/Performance Costs of Software Cryptography in.pdf:PDF},
  keywords = {Industrial Internet of Things, Internet of Energy, Embedded Security, Smart Grid.},
  url      = {file:///C:/Users/khiyra009gmail.com/Downloads/Cryptography/Cryptography/Performance%20Costs%20of%20Software%20Cryptography%20in.pdf},
}

@Article{JaihuiChen2018,
  author   = {Jaihui Chen, Chik How Tan, and Xiaoyu Li},
  title    = {Practical Cryptanalysis of a Public Key Cryptosystem Based on the Morphism of Polynomials Problem},
  journal  = {IEEE},
  year     = {2018},
  volume   = {23},
  number   = {6},
  pages    = {9},
  month    = dec,
  abstract = {Multivariate Public Key Cryptography (MPKC) has intensively and rapidly developed during the past three decades. MPKC is a promising candidate for post-quantum cryptography. However, designing it is universally
regarded as a difficult task to design a secure MPKC foundation scheme, such as an encryption scheme and key exchange scheme. In this work, we investigate the security of a new public key cryptosystem that is based on the Morphism of Polynomials (MP). The public key cryptosystem proposed by Wang et al. (Wuhan University, China) comprises a key exchange scheme and encryption scheme. Its security can be provably reduced to the hardness of solving a new difficult problem, namely, the Decisional Multivariate Diffie Hellman (DMDH) problem. This problem is a variant of the MP problem, which is difficult to solve by random systems. We present a proposition that reduces the DMDH problem to an easy example of the MP problem. Then, we propose an efficient algorithm for the Key Recover Attack (KRA) on the schemes of the public key cryptosystem. In practice, we are able to entirely break the cryptosystem’s claimed parameter of 96 security levels in less than 17.252 s. Furthermore, we show that finding parameters that yield a secure and practical scheme is impossible},
  file     = {:Cryptography/Practical Cryptanalysis of a Public Key Cryptosystem.pdf:PDF},
  keywords = {cryptanalysis; post-quantum cryptography; multivariate public key cryptosystems; morphism of polynomials problem},
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=Practical+Cryptanalysis+of+a+Public+Key+Cryptosystem+Based+on+the+Morphism+of+Polynomials+Problem&btnG=},
}

@Article{MasahideSasaki2015,
  author   = {Masahide Sasaki, Mikio Fujiwara, Rui-Bo Jin, Masahiro Takeoka, Te Sun Han, Fellow, IEEE, Hiroyuki Endo, Ken-Ichiro Yoshino, Takao Ochi, Shione Asami, and Akio Tajima, Member, IEEE},
  title    = {Quantum Photonic Network: Concept, Basic Tools, and Future Issues},
  journal  = {IEEE},
  year     = {2015},
  volume   = {21},
  number   = {3},
  pages    = {13},
  month    = jun,
  abstract = {We present practical GHz-clocked QKD systems, next
generation entanglement QKD technologies, and QKD platform to
manage the secure keys and to support a variety of applications.
We then show the intrinsic limit of QKD, i.e., a key rate bound, and
discuss how to realize the provable (information theoretic) security
with a larger secrecy capacity over longer distances. In particular,
we present a basic theory of physical layer cryptography, which
characterizes the secrecy capacity, and engineers the tradeoff between
the efficiency of reliable transmission and secrecy of communication.
We introduce a concept to unify these schemes in photonic
network, referred to as quantum photonic network. Future issues
for realizing this new network paradigm are discussed},
  file     = {:Cryptography/Quantum Photonic Network.pdf:PDF},
  keywords = {Quantum Photonic Network: Concept, Basic Tools, and Future Issues},
  url      = {file:///C:/Users/khiyra009gmail.com/Downloads/Cryptography/Cryptography/Quantum%20Photonic%20Network.pdf},
}

@Article{ZUOWEN2018,
  author   = {ZUOWEN TAN},
  title    = {Secure Delegation-Based Authentication for Telecare Medicine Information Systems},
  journal  = {IEEE},
  year     = {2018},
  volume   = {6},
  pages    = {20},
  month    = may,
  abstract = {The telecare medicine information systems (TMISs) enable patients to gain health monitoring
at home and obtain medical services over mobile networks. In recent years, many authentication
schemes have been proposed to address the security and privacy issues in the TMISs. For example,
Kim et al. and Huang et al. proposed efficient delegation-based authentication protocols by using elliptic
curve cryptography. These protocols have a prerequisite that both the home location register and the visited
location register must share secrets beforehand. In this paper, we show that Kim et al.’s and Hwang et al.’s
schemes are vulnerable to known key attacks. Moreover, they fail to provide communication confidentiality.
We then present a new secure delegation-based authentication protocol by using the identity-based cryptography.
The proposed protocol removes the weaknesses of the above-mentioned protocols. Through the
analysis of the Burrows–Abadi–Needham logic, along with a random oracle model, we demonstrate that the
proposed scheme provides secure authentication. In addition, the proposed scheme can provide more security
functionaries than the existing delegation-based authentication protocols. Better tradeoff among security and
functionality features and communication and computation costs makes our scheme suitable and applicable
in the TMISs.},
  file     = {:Cryptography/Secure Delegation-Based Authentication for telecare syatem.pdf:PDF},
  keywords = {Authentication, BAN, cryptography, delegation.},
  url      = {file:///C:/Users/khiyra009gmail.com/Downloads/Cryptography/Cryptography/Secure%20Delegation-Based%20Authentication%20for%20telecare%20syatem.pdf},
}

@Article{MOHAMMEDA.M.ABDULLAH2016,
  author   = {MOHAMMED A. M. ABDULLAH, (Member, IEEE), SATNAM S. DLAY, (Member, IEEE), WAI L. WOO, (Senior Member, IEEE), AND JONATHON A. CHAMBERS, (Fellow, IEEE)},
  title    = {A Framework for Iris Biometrics Protection: A Marriage Between Watermarking and Visual Cryptography},
  journal  = {IEEE},
  year     = {2016},
  volume   = {4},
  pages    = {14},
  month    = oct,
  abstract = {This paper presents a novel security architecture for protecting the integrity of iris images
and templates using watermarking and visual cryptography (VC). The proposed scheme offers a complete
protection framework for the iris biometrics which consists of two stages: the first stage is for iris image
protection, while the second is for the iris template. First, for protecting the iris image, a watermark text
which carries personal information is embedded in the middle band frequency region of the iris image using
a novel watermarking algorithm that randomly interchanges multiple middle band pairs of the discrete cosine
transform. Second, for iris template protection, the binary iris template is divided into two shares using VC,
where one share is stored in the database and the other is kept with the user on a smart card. In addition,
the SHA-2 hash function is utilized to maintain the integrity of the stored iris template in both the database
and smart card. The experimental and comparison results on the CASIA V4 and UBIRIS V1 iris databases
demonstrate that the proposed framework preserves the privacy of the iris images and templates and retains
robustness to malicious attacks, while it does not have a discernible effect on the recognition performance},
  file     = {:Cryptography/Watermarking and Visual Cryptography.pdf:PDF},
  keywords = {Biometrics, iris recognition, security and privacy protection, watermarking, smart card, template security, visual cryptography.},
  url      = {file:///C:/Users/khiyra009gmail.com/Downloads/Cryptography/Cryptography/Watermarking%20and%20Visual%20Cryptography.pdf},
}

@Article{JinhuiLiu2016,
  author   = {Jinhui Liu, Aiwan Fan, Jianwei Jia, Huanguo Zhang , Houzhen Wang, and Shaowu Mao},
  title    = {Cryptanalysis of Public Key Cryptosystems Based on Non-Abelian Factorization Problems},
  journal  = {IEEE},
  year     = {2016},
  volume   = {21},
  number   = {3},
  pages    = {8},
  month    = jun,
  abstract = {t: Advances in quantum computers threaten to break public-key cryptosystems (e.g., RSA, ECC, and
EIGamal), based on the hardness of factoring or taking a discrete logarithm. However, no quantum algorithms
have yet been found for solving certain mathematical problems in non-commutative algebraic structures. Recently,
two novel public-key encryption schemes, BKT-B cryptosystem and BKT-FO cryptosystem, based on factorization
problems have been proposed at Security and Communication Networks in 2013. In this paper we show that these
two schemes are vulnerable to structural attacks and linearization equations attacks, and that they only require
polynomial time complexity to obtain messages from associated public keys. We conduct a detailed analysis of
the two attack methods and show corresponding algorithmic descriptions and efficiency analyses. In addition, we
provide some improvement suggestions for the two public-key encryption schemes.},
  file     = {:Cryptography/Cryptanalysis of Public Key Cryptosystems Based.pdf:PDF},
  keywords = {cryptography; post-quantum cryptography; public key encryption; cryptanalysis; linear equations},
  url      = {file:///C:/project/FYP%20done/RPs/Cryptography/Cryptanalysis%20of%20Public%20Key%20Cryptosystems%20Based.pdf},
}

@Article{THANHNAMPHAM2015,
  author   = {THANH NAM PHAM, MING-FONG TSAI, DUC BINH NGUYEN,CHYI-REN DOW, AND DER-JIUNN DENG},
  title    = {A Cloud-Based Smart-Parking System Based on Internet-of-Things Technologies},
  journal  = {IEEE},
  year     = {2015},
  volume   = {3},
  pages    = {11},
  month    = sep,
  abstract = {This paper introduces a novel algorithm that increases the efficiency of the current cloud-based smart-parking system and develops a network architecture based on the Internet-of-Things technology. This paper proposed a system that helps users automatically find a free parking space at the least cost based on new performance metrics to calculate the user parking cost by considering the distance and the total number of free places in each car park. This cost will be used to offer a solution of finding an available parking space upon a request by the user and a solution of suggesting a new car park if the current car park is full. The simulation results show that the algorithm helps improve the probability of successful parking and minimizes the user waiting time. We also successfully implemented the proposed system in the real world.},
  file     = {:Artificial Intelligence/A Cloud-Based Smart-Parking System Based.pdf:PDF},
  keywords = {Smart-parking system, performance metrics},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/A%20Cloud-Based%20Smart-Parking%20System%20Based.pdf},
}

@Article{JAMESGERARDWOLFF2015,
  author   = {JAMES GERARD WOLFF, (Member, IEEE)},
  title    = {The SP Theory of Intelligence: Distinctive Features and Advantages},
  journal  = {IEEE},
  year     = {2015},
  volume   = {4},
  pages    = {31},
  month    = dec,
  abstract = {This paper aims to highlight distinctive features of the SP theory of intelligence, realized in the SP computer model, and its apparent advantages compared with some AI-related alternatives. Perhaps most importantly, the theory simplifies and integrates observations and concepts in AI-related areas, and has potential to simplify and integrate of structures and processes in computing systems. Unlike most other AI-related theories, the SP theory is itself a theory of computing, which can be the basis for new architectures for computers. Fundamental in the theory is information compression via the matching and unification of patterns and, more specifically, via a concept of multiple alignment. The theory promotes transparency in the representation and processing of knowledge, and unsupervised learning of natural structures via information compression. It provides an interpretation of aspects of mathematics and an interpretation of phenomena in human perception and cognition. Abstract concepts in the theory may be realized in terms of neurons and their inter-connections (SP-neural). These features and advantages of the SP system are discussed in relation to AI-related alternatives: the concept of minimum length encoding and related concepts, how computational and energy efficiency in computing may be achieved, deep learning in neural networks, unified theories of cognition and related research, universal search, Bayesian networks and some other models for AI, IBM’s Watson, solving problems associated with big data and in the development of intelligence in autonomous robots, pattern recognition and vision, the learning and processing of natural language, exact and inexactm forms of reasoning, representation and processing of diverse forms of knowledge, and software engineering. In conclusion, the SP system can provide a firm foundation for the long-term development of AI and related areas, and at the same time, it may deliver useful results on relatively short timescales.},
  file     = {:Artificial Intelligence/AI The SP Theory of Intelligence Distinctive.pdf:PDF},
  keywords = { Artificial intelligence, information compression, multiple alignment, perception, cognition, neural networks, deep learning, unsupervised learning, reasoning, mathematics.},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/AI%20The%20SP%20Theory%20of%20Intelligence%20Distinctive.pdf},
}

@Article{PETROVIC2018,
  author   = {VLADIMIR M. PETROVIĆ},
  title    = {Artificial Intelligence and Virtual Worlds – Toward Human-Level AI Agents},
  journal  = {IEEE},
  year     = {2018},
  volume   = {6},
  pages    = {13},
  month    = jul,
  abstract = {Artificial Intelligence (AI) has a long tradition as a scientific field, with tremendous achievements accomplished in the decades behind us. At the same time, in the last few decades, we have witnessed a rising popularity of interactive computer games and multi-user virtual environments, resulting with millions of users inhabiting these virtual worlds. This paper deals with the intersection of AI and virtual worlds, focusing on AI agents and exploring the potential implications toward the human-level AI. It offers a unique multidisciplinary approach to the subject, in order to give a comprehensive view on the elaborated problems and the way they are interrelated. Benefits coming from this kind of broad study are twofold: on one hand, research on advanced AI agents in the virtual worlds is the necessary ingredient of their further evolution; and on the other hand, the virtual worlds represent an excellent platform for research on numerous problems related to the challenging field of AI.},
  file     = {:Artificial Intelligence/Artificial Intelligence and Virtual Worlds –.pdf:PDF},
  keywords = {Artificial intelligence, autonomous intelligent agents, human-level AI, machine learning, interactive computer games, MUVEs, virtual worlds.},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/Artificial%20Intelligence%20and%20Virtual%20Worlds%20–.pdf},
}

@Article{JIAFUWAN2018,
  author   = {JIAFU WAN, JUN YANG, ZHONGREN WANG, (Member, IEEE), AND QINGSONG HUA},
  title    = {Artificial Intelligence for Cloud-Assisted Smart Factory},
  journal  = {IEEE},
  year     = {2018},
  volume   = {6},
  pages    = {12},
  month    = sep,
  abstract = {In the context of industry 4.0, the main way to realize the intelligent manufacturing is to build a smart factory integrated with the advanced technologies, such as the Internet of Things (IoT), cloud computing, and artificial intelligence (AI). With the aim to emphasize the role and potential of cloud computing and AI in improving the smart factories’ performances, such as system flexibility, efficiency, and intelligence, we comprehensively summarize and explain the AI application in a cloud-assisted smart factory (CaSF). In this paper, a vertically-integrated four-tier CaSF architecture is presented. Also, the key AI technologies involved in the CaSF are classified and described according to the logical relationships in the architecture hierarchy. Finally, the main issues and technical challenges of AI technologies in the CaSF systems are introduced, and some possible solutions are also given. The application of the AI in smart factories has accelerated the implementation of the industry 4.0 to the certain extent.},
  file     = {:Artificial Intelligence/Artificial Intelligence for Cloud-Assisted.pdf:PDF},
  keywords = {Artificial intelligence, cloud computing, Industry 4.0, smart factory},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/Artificial%20Intelligence%20for%20Cloud-Assisted.pdf},
}

@Article{JIAYINGLIU2018,
  author   = {JIAYING LIU, XIANGJIE KONG, (Senior Member, IEEE),FENG XIA, (Senior Member, IEEE), XIAOMEI BAI,LEI WANG, QING QING, AND IVAN LEE3, (Senior Member, IEEE)},
  title    = {Artificial Intelligence in the 21st Century},
  journal  = {IEEE},
  year     = {2018},
  volume   = {6},
  pages    = {19},
  month    = mar,
  abstract = {The field of artificial intelligence (AI) has shown an upward trend of growth in the 21st century (from 2000 to 2015). The evolution in AI has advanced the development of human society in our own time, with dramatic revolutions shaped by both theories and techniques. However, the multidisciplinary and fastgrowing features make AI a field in which it is difficult to be well understood. In this paper, we study the evolution of AI at the beginning of the 21st century using publication metadata extracted from 9 top-tier journals and 12 top-tier conferences of this discipline. We find that the area is in the sustainable development and its impact continues to grow. From the perspective of reference behavior, the decrease in self-references indicates that the AI is becoming more and more open-minded. The influential papers/researchers/institutions we identified outline landmarks in the development of this field. Last but not least, we explore the inner structure in terms of topics’ evolution over time. We have quantified the temporal trends at the topic level and discovered the inner connection among these topics. These findings provide deep insights into the current scientific innovations, as well as shedding light on funding policies.},
  file     = {:Artificial Intelligence/Artificial Intelligence in the 21st Century.pdf:PDF},
  keywords = {Artificial intelligence, data analytics, scientific impact, science of science, data science},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/Artificial%20Intelligence%20in%20the%2021st%20Century.pdf},
}

@Article{LINYUAN2018,
  author   = {LIN YUAN , XUE WEI, HUI SHEN, LING-LI ZENG , AND DEWEN HU , (Senior Member, IEEE)},
  title    = {Multi-Center Brain Imaging Classification Using a Novel 3D CNN Approach},
  journal  = {IEEE},
  year     = {2018},
  volume   = {6},
  pages    = {10},
  month    = sep,
  abstract = {With the development of brain imaging technology, increasing amounts of magnetic resonance imaging data are being acquired, and traditional computational analysis methods based on single sites and small samples are facing substantial challenges. Deep learning technology, which is born via artificial intelligence, has shown the powerful ability to solve the classification problem based on big data in many studies, while it has not been widely used in brain imaging classification. Herein, we utilized our proposed novel 3-D deep adding neural network to classify 6008 samples from the largest data sets in the brain imaging field collected from more than 61 centers. The proposed method utilizes multiple convolutional layers to extract gradient information in different orientations and combines spatial information at two scales via the adding operation. High accuracy (over 92.5%) was obtained with a standard fivefold cross-validation strategy, demonstrating that the proposed method can effectively handle big data classifications from multiple centers. Compared with some traditional classification methods and some deep learning architectures, the proposed method was more accurate, demonstrating its stronger power to classify data from multiple centers. Our cross-site classification results prove that the proposed method is robust when training on a data set and testing on another data set. To the best of our knowledge, this paper is the first to classify neuroimaging data on such a large scale from multiple centers with such high accuracy. With its improved performance in classification and transferable program codes, the proposed method can potentially be used
in intelligent medical treatment strategies and clinical practices based on mobile terminal.},
  file     = {:Artificial Intelligence/Artificial Intelligence Multi-Center Brain Imaging Classification.pdf:PDF},
  keywords = {Artificial intelligence, artificial neural networks, image classification, machine learning, magnetic resonance imaging.},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/Artificial%20Intelligence%20Multi-Center%20Brain%20Imaging%20Classification.pdf},
}

@Article{ZONGBAOYANG2018,
  author   = {ZONGBAO YANG , SHAOHONG ZHANG, WENJUN SHEN, XIAOFEI XING, (Member, IEEE), AND YING GAO},
  title    = {Artificial Intelligence Related Publication Analysis Based on Citation Counting},
  journal  = {IEEE},
  year     = {2018},
  volume   = {6},
  pages    = {13},
  month    = sep,
  abstract = {Artificial intelligence is one of the most popular technologies in recently years. Journals and conferences are widely viewed as major tools to track the development of technologies. Citation counting analysis is one of the most acknowledged metrics in spite of its controversial drawbacks. To the best of our knowledge, most methods based on citation counting do not taken into account the citation weight in different years. In this paper, we focused on citation counting and designed a scheme to calculate both the citation weight and weighting of the cited credits of different publications, which are used to verify the efficiency of the proposed scheme. We also evaluated the popularity of publications by calculating their popularity scores. Unlike other ranking regulations, our proposed measure was able to compare journals and conferences simultaneously. In addition, we extracted ranking results to calculate the pairwise similarity via a generalized measure, which provided a more objective insight into the differences between publications. Several interesting observations were found from the experimental results with real data.},
  file     = {:Artificial Intelligence/Artificial Intelligence Related Publication.pdf:PDF},
  keywords = {Artificial intelligence, citation counting, recommendation lists},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/Artificial%20Intelligence%20Related%20Publication.pdf},
}

@Article{FERNANDOORTEGA2018,
  author   = {FERNANDO ORTEGA , JESÚS BOBADILLA , ABRAHAM GUTIÉRREZ, REMIGIO HURTADO AND XIN LI},
  title    = {Artificial Intelligence Scientific Documentation, Dataset for Recommender Systems},
  journal  = {IEEE},
  year     = {2018},
  volume   = {6},
  pages    = {13},
  month    = aug,
  abstract = {The existing scientific documentation-based recommender systems focus on exploiting the citations and references information included in each research paper and also the lists of co-authors. In this way, it can be addressed the recommendation of related papers and even related authors. The approach we propose is original because instead of using each paper citations and co-authors, we relate each of the papers with their main research topics. This approach provides a semantic level superior to that currently used, which allows us to obtain useful results. We can use collaborative filtering recommender systems to recommend research topics related to each paper and also to recommend papers related to each research topic. In order to face this innovative proposal, we have solved a series of challenges that allow us to offer various resources and results in the paper. Our main contributions are: 1) making a data mining of scientific documentation; 2) creating and publishing an open database containing the data mining results; 3) extracting the research topics from the available scientific documentation; 4) creating and publishing a recommender system data set obtained from the database and the research topics; 5) testing the data set through a complete set of collaborative filtering methods and quality measures; and 6) selecting and showing the best methods and results, obtained using the open data set, in the context of scientific documentation recommendations. Results of the paper show the suitability of the provided data set in collaborative filtering processes, as well as the superiority of the model-based methods to face scientific documentation recommendations.},
  file     = {:Artificial Intelligence/Artificial Intelligence Scientific Documentation.pdf:PDF},
  keywords = {S Dataset, scientific documentation, recommender systems, machine learning, data mining, artificial intelligence, Scopus, topics.},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/Artificial%20Intelligence%20Scientific%20Documentation.pdf},
}

@Article{G.PankajJain2014,
  author   = {G. Pankaj Jain, Varadraj P. Gurupur, Jennifer L. Schroeder, and Eileen D. Faulkenberry},
  title    = {Artificial Intelligence-Based Student Learning Evaluation: A Concept Map-Based Approach for Analyzing a Student’s Understanding of a Topic},
  journal  = {IEEE},
  year     = {2014},
  volume   = {7},
  number   = {3},
  pages    = {13},
  month    = sep,
  abstract = {In this paper, we describe a tool coined as artificial intelligence-based student learning evaluation tool (AISLE). The main purpose of this tool is to improve the use of artificial intelligence techniques in evaluating a student’s understanding of a particular topic of study using concept maps. Here, we calculate the probability distribution of the concepts identified in the concept map developed by the student. The evaluation of a student’s understanding of the topic is assessed by analyzing the curve of the graph generated by this tool. This technique makes extensive use of XML parsing to perform the required evaluation. The tool was successfully tested with students from two undergraduate courses and the results of testing are described in this paper.},
  file     = {:Artificial Intelligence/Artificial Intelligence-Based Student Learning.pdf:PDF},
  keywords = {Concept maps, evaluation, probability distributions, XML parsers},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/Artificial%20Intelligence-Based%20Student%20Learning.pdf},
}

@Article{XIAOFEIWANG2015,
  author   = {XIAOFEI WANG, (Member, IEEE), XIUHUA LI, (Student Member, IEEE), AND VICTOR C. M. LEUNG, (Fellow, IEEE)},
  title    = {Artificial Intelligence-Based Techniques for Emerging Heterogeneous Network: State of the Arts, Opportunities, and Challenges},
  journal  = {IEEE},
  year     = {2015},
  volume   = {3},
  pages    = {13},
  month    = aug,
  abstract = {Recently, mobile networking systems have been designed with more complexity of infrastructure and higher diversity of associated devices and resources, as well as more dynamical formations of networks, due to the fast development of current Internet and mobile communication industry. In such emerging mobile heterogeneous networks (HetNets), there are a large number of technical challenges focusing on the efficient organization, management, maintenance, and optimization, over the complicated system resources. In particular, HetNets have attracted great interest from academia and industry in deploying more effective solutions based on artificial intelligence (AI) techniques, e.g., machine learning, bio-inspired algorithms, fuzzy neural network, and so on, because AI techniques can naturally handle the problems of large-scale complex systems, such as HetNets towards more intelligent and automatic-evolving ones. In this paper, we discuss the state-of-the-art AI-based techniques for evolving the smarter HetNets infrastructure and systems, focusing on the research issues of self-configuration, self-healing, and self-optimization, respectively. A detailed taxonomy of the related AI-based techniques of HetNets is also shown by discussing the pros and cons for various AI-based techniques for different problems in HetNets. Opening research issues and pending challenges are concluded as well, which can provide guidelines for future research work.},
  file     = {:Artificial Intelligence/Artificial Intelligence-Based Techniques for.pdf:PDF},
  keywords = {Artificial intelligence, genetic algorithms, ant colony optimization, self-organization networks, heterogeneous networks.},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/Artificial%20Intelligence-Based%20Techniques%20for.pdf},
}

@Article{JAMESGERARDWOLFF2014,
  author   = {JAMES GERARD WOLFF, (Member, IEEE)},
  title    = {Autonomous Robots and the SP Theory of Intelligence},
  journal  = {IEEE},
  year     = {2014},
  volume   = {2},
  pages    = {23},
  month    = dec,
  abstract = {This paper is about how the SP theory of intelligence and its realization in the SP machine (both outlined in this paper) may help in the design of the brains of autonomous robots, meaning robots that do not depend on external intelligence or power supplies, are mobile, and have human-like versatility and adaptability in intelligence. This paper addresses three main problems: 1) how to increase the computational and energy efficiency of computers and to reduce their size and weight; 2) how to achieve human-like versatility in intelligence; and 3) likewise for human-like adaptability in intelligence. Regarding the first problem, the SP system has the potential for substantial gains in computational efficiency, with corresponding cuts in energy consumption and the bulkiness of computers: 1) by reducing the size of data to be processed; 2) by exploiting statistical information that the system gathers as an integral part of how it works; and 3) via a new version of Donald Hebb’s concept of a cell assembly. Toward human-like versatility in intelligence, the SP system has strengths in unsupervised learning, natural language processing, pattern recognition, information retrieval, several kinds of reasoning, planning, problem solving, and more, with seamless integration among structures and functions. The SP system’s strengths in unsupervised learning and other aspects of intelligence may help in achieving human-like adaptability in intelligence via: 1) one-trial learning; 2) learning of natural language; 3) learning to see; 4) building 3-D models of objects and of a robot’s surroundings; 5) learning regularities in the workings of a robot and in the robot’s environment; 6) exploration and play; 7) learning major skills; and 8) learning via demonstration. Also discussed are how the SP system may process parallel streams of information, generalization of knowledge, correction of over-generalizations, learning from dirty data, how to cut the cost of learning, and reinforcements and motivations},
  file     = {:Artificial Intelligence/Autonomous Robots and the Artificial.pdf:PDF},
  keywords = {Artificial intelligence, robots, cognitive science, data compression, pattern recognition, unsupervised learning.},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/Autonomous%20Robots%20and%20the%20Artificial.pdf},
}

@Article{MIRZAGOLAMKIBRIA2018,
  author   = {MIRZA GOLAM KIBRIA , (Member, IEEE), KIEN NGUYEN , (Senior Member, IEEE), GABRIEL PORTO VILLARDI , (Senior Member, IEEE), OU ZHAO, KENTARO ISHIZU, AND FUMIHIDE KOJIMA, (Member, IEEE)},
  title    = {Big Data Analytics, Machine Learning, and Artificial Intelligence in Next-Generation Wireless Networks},
  journal  = {IEEE},
  year     = {2018},
  volume   = {16},
  pages    = {11},
  month    = may,
  abstract = {The next-generation wireless networks are evolving into very complex systems becauseof the very diversified service requirements, heterogeneity in applications, devices, and networks. The network operators need to make the best use of the available resources, for example, power, spectrum, as well as infrastructures. Traditional networking approaches, i.e., reactive, centrally-managed, one-sizefits-all approaches, and conventional data analysis tools that have limited capability (space and time) are not competent anymore and cannot satisfy and serve that future complex networks regarding operation and optimization cost effectively. A novel paradigm of proactive, self-aware, self-adaptive, and predictive networking is much needed. The network operators have access to large amounts of data, especially fromthe network and the subscribers. Systematic exploitation of the big data dramatically helps in making the system smart, intelligent, and facilitates efficient as well as cost-effective operation and optimization. We envision data-driven next-generation wireless networks, where the network operators employ advanced data analytics, machine learning (ML), and artificial intelligence. We discuss the data sources and strong drivers for the adoption of the data analytics, and the role of ML, artificial intelligence in making the system intelligent regarding being self-aware, self-adaptive, proactive and prescriptive. A set of network design and optimization schemes are presented concerning data analytics. This paper concludes with a discussion of challenges and the benefits of adopting big data analytics, ML, and artificial intelligence in the nextgeneration communication systems.},
  file     = {:Artificial Intelligence/Big Data Analytics, Machine Learning, and Artificial.pdf:PDF},
  keywords = {Big data analytics, machine learning, artificial intelligence, next-generation wireless.},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/Big%20Data%20Analytics,%20Machine%20Learning,%20and%20Artificial.pdf},
}

@Article{DU-MIM2015,
  author   = {DU-MIM YOON AND KYUNG-JOONG KIM},
  title    = {Challenges and Opportunities in Game Artificial Intelligence Education Using Angry Birds},
  journal  = {IEEE},
  year     = {2015},
  volume   = {3},
  pages    = {12},
  month    = jun,
  abstract = {Games have been an important tool for motivating undergraduate students majoring in computer science and engineering. However, it is difficult to build an entire game for education from scratch, because the task requires high-level programming skills and expertise to understand the graphics and physics. Recently, there have been many different game artificial intelligence (AI) competitions, ranging from board games to the state-of-the-art video games (car racing, mobile games, first-person shooting games, real-time strategy games, and so on). The competitions have been designed such that participants develop their own AI module on top of public/commercial games. Because the materials are open to the public, it is quite useful to adopt them for an undergraduate course project. In this paper, we report our experiences using the Angry Birds AI Competition for such a project-based course. In the course, teams of students consider computer vision, strategic decision-making, resource management, and bug-free coding for their outcome. To promote understanding of game contents generation and extensive testing on the generalization abilities of the student’s AI program, we developed software to help them create user-created levels. Students actively participated in the project and the final outcome was comparable with that of successful entries in the 2013 International Angry Birds AI Competition. Furthermore, it leads to the development of a new parallelized Angry Birds AI Competition platform with undergraduate students aiming to use advanced optimization algorithms for their controllers. },
  file     = {:Artificial Intelligence/Challenges and Opportunities in Game Artificial.pdf:PDF},
  keywords = { Computing education, Angry Birds, game, edutainment, program design, artificialmintelligence (AI), game competition, game-based learning.},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/Challenges%20and%20Opportunities%20in%20Game%20Artificial.pdf},
}

@Article{ShirLiWang2017,
  author   = {Shir Li Wang, Kamran Shafi, Member, IEEE, Theam Foo Ng, Member, IEEE, Chris Lokan, and Hussein A. Abbass, Senior Member, IEEE},
  title    = {Contrasting Human and Computational Intelligence Based Autonomous Behaviors in a Blue–Red Simulation Environment},
  journal  = {IEEE},
  year     = {2017},
  volume   = {1},
  number   = {1},
  pages    = {14},
  month    = feb,
  abstract = {Autonomous systems are making their way to the market. The transition from tasks performed by humans to tasks performed by machines begs for an answer to one of the most challenging questions in this area of research: Will humans understand and trust what a machine does? Analyzing human and machine behaviors offers the foundational steps toward finding answers to this question. This paper contributes a novel  methodology for transforming low-level actions by each agent into high-level categorization of strategies to contrast the behaviors of humans and machines using a computational red teaming environment with a red (evader) and a blue (pursuer) agent. Two orthogonal sources of uncertainty were examined: the uncertainty in the blue agent’s situation awareness about the red, and the red agent’s uncertainty resulting from deceptive actions by the blue. For each uncertainty source, two different experiments were conducted by varying the controller of the red agent. In one experiment, the red agent was controlled by one of the 34 human subjects; and in the second, by an evolved neural network. The blue agent was controlled by a scripted rule-based system. In this time-critical task, the results revealed that humans tend to follow systemic and consistent strategies,
sometimes ignoring the information available to them. On the other hand, machines tend to evolve more complex and diverse strategies. This finding calls for new computational intelligence techniques to enable the fusion of these different strategies into forms that each party can understand and use effectively.},
  file     = {:Artificial Intelligence/Contrasting Human and Computational Intelligence.pdf:PDF},
  keywords = {Computational red teaming, human-machine behavioral analysis transparent artificial intelligence transparent autonomy, neuro-evolution.},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/Contrasting%20Human%20and%20Computational%20Intelligence.pdf},
}

@Article{YANGXIN2018,
  author   = {YANG XIN, LINGSHUANG KONG , ZHI LIU, (Member, IEEE), YULING CHEN, YANMIAO LI, HONGLIANG ZHU, MINGCHENG GAO ,HAIXIA HOU, AND CHUNHUA WANG},
  title    = {Machine Learning and Deep Learning Methods for Cybersecurity},
  journal  = {IEEE},
  year     = {2018},
  volume   = {6},
  pages    = {17},
  month    = may,
  abstract = {With the development of the Internet, cyber-attacks are changing rapidly and the cyber security situation is not optimistic. This survey report describes key literature surveys on machine learning (ML) and deep learning (DL) methods for network analysis of intrusion detection and provides a brief tutorial description of each ML/DL method. Papers representing each method were indexed, read, and summarized based on their temporal or thermal correlations. Because data are so important in ML/DL methods, we describe some of the commonly used network datasets used in ML/DL, discuss the challenges of using ML/DL for cybersecurity and provide  suggestions for research directions.},
  file     = {:Artificial Intelligence/Machine Learning and Deep Learning.pdf:PDF},
  keywords = {Cybersecurity, intrusion detection, deep learning, machine learning.},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/Machine%20Learning%20and%20Deep%20Learning.pdf},
}

@Article{Hettiarachchi2014,
  author   = {Gayan Prasad Hettiarachchi, Dhammika Suresh Hettiarachchi , Nadeeka Nilmini Hettiarachchi , Azusa Ebisuya},
  title    = {Next Generation Data Classification and Linkage Role of Probabilistic Models and Artificial Intelligence},
  journal  = {IEEE},
  year     = {2014},
  pages    = {8},
  abstract = {Data classification and linkage is the task of identifying information corresponding to the same entity from one or more data sources. Methods used to tackle data classification and linkage problems fall into two broad
categories. One commonly used method is deterministic models, in which sets of often very complex rules are used to classify pairs of entities as links. The other is the probabilistic model, in which statistical or probabilistic approaches are used to classify pairs. However, these models fail to deliver when there are lots of missing values, typographical errors, non-standardized entities, etc. To this end, intelligent routines making use of
artificial neural networks, genetic algorithms and clustering algorithms can provide the next generation models for data classification and linkage. An introduction to data linkage, impact on humanity and community, current models, associated pitfalls, new directions and issues both technical and social for next generation data classification and linkage systems are discussed using an example prototype. A new model for linkage
is proposed, where it is highlighted that not only the relationships between attributes of different entities, but also identification of relationships within the attributes of an entity is important in handling missing values and can provide better accuracy.},
  file     = {:Artificial Intelligence/Next Generation Data Classification and Linkage  AI.pdf:PDF},
  keywords = {Big data; classification; data linkage; machine learning; phonetic matching; probabilistic models; string comparison },
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/Next%20Generation%20Data%20Classification%20and%20Linkage%20%20AI.pdf},
}

@Article{Fei-YueWang2017,
  author   = {Fei-Yue Wang, Fellow, IEEE, Nan-Ning Zheng, Fellow, IEEE, Dongpu Cao, Member, IEEE, Clara Marina Martinez, Li Li, Fellow, IEEE, and Teng Liu},
  title    = {Parallel Driving in CPSS: A Unified Approach for Transport Automation and Vehicle Intelligence},
  journal  = {IEEE},
  year     = {2017},
  volume   = {4},
  number   = {4},
  pages    = {11},
  month    = oct,
  abstract = {The emerging development of connected and automated vehicles imposes a significant challenge on current vehicle control and transportation systems. This paper proposes a novel unified approach, Parallel Driving, a cloud-based cyberphysical-social systems (CPSS) framework aiming at synergizing connected automated driving. This study first introduces the CPSS and ACP-based intelligent machine systems. Then the parallel driving is proposed in the cyber-physical-social space, considering interactions among vehicles, human drivers, and information. Within the framework, parallel testing, parallel learning and parallel reinforcement learning are  eveloped and concisely reviewed. Development on intelligent horizon (iHorizon) and its applications are also presented towards parallel horizon. The proposed parallel driving offers an ample solution for achieving
a smooth, safe and efficient cooperation among connected automated vehicles with different levels of automation in future road transportation systems.},
  file     = {:Artificial Intelligence/Parallel Driving in CPSS for vehicle intelligence.pdf:PDF},
  keywords = {ACP theory, connected automated driving, cyber-physical-social systems (CPSS), iHorizon, parallel driving, parallel horizon, parallel learning, parallel reinforcement learning, parallel testing},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/Parallel%20Driving%20in%20CPSS%20for%20vehicle%20intelligence.pdf},
}

@Article{ADADI2018,
  author   = {AMINA ADADI AND MOHAMMED BERRADA},
  title    = {Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI)},
  journal  = {IEEE},
  year     = {2018},
  volume   = {6},
  pages    = {23},
  month    = sep,
  abstract = {At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artificial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research field holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI. Through the lens of the literature, we review the existing approaches regarding the topic, discuss trends surrounding its sphere, and present major research trajectories.},
  file     = {:Artificial Intelligence/Peeking Inside the Black-Box- A Survey on AI.pdf:PDF},
  keywords = {Explainable artificial intelligence, interpretable machine learning, black-box models.},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/Peeking%20Inside%20the%20Black-Box-%20A%20Survey%20on%20AI.pdf},
}

@Article{MAN-JEKIM2018,
  author   = {MAN-JE KIM, KYUNG-JOONG KIM, SEUNGJUN KIM, AND ANIND K. DEY},
  title    = {Performance Evaluation Gaps in a Real-Time Strategy Game Between Human and Artificial Intelligence Players},
  journal  = {IEEE},
  year     = {2018},
  volume   = {6},
  pages    = {12},
  month    = jan,
  abstract = {Since 2010, annual StarCraft artificial intelligence (AI) competitions have promoted the development of successful AI players for complex real-time strategy games. In these competitions, AI players are ranked based on their win ratio over thousands of head-to-head matches. Although simple and easily implemented, this evaluation scheme may less adequately help develop more human-competitive AI players. In this paper, we recruited 45 human StarCraft players at different expertise levels (expert/medium/novice)  and asked them to play against the 18 top AI players selected from the five years of competitions (2011–2015). The results show that the human evaluations of AI players differ substantially from the current  standard evaluation and ranking method. In fact, from a human standpoint, there has been little progress in the quality of StarCraft AI players over the years. It is even possible that AI-only tournaments can lead to AIs being created that are unacceptable competitors for humans. This paper is the first to systematically explore the human evaluation of AI players, the evolution of AI players, and the differences between human perception and tournament-based evaluations. The discoveries from this paper can support AI developers in game companies and AI tournament organizers to better incorporate the perspective of human users into their AI systems.},
  file     = {:Artificial Intelligence/Performance Evaluation Gaps in a Real-Time Artificial Intelligence.pdf:PDF},
  keywords = {Video game, Starcraft, game, artificial intelligence, game AI competition, human factor, human computer interaction},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/Performance%20Evaluation%20Gaps%20in%20a%20Real-Time%20Artificial%20Intelligence.pdf},
}

@Article{MaxOrtiz-Catalan2014,
  author   = {Max Ortiz-Catalan, Member, IEEE, Bo Håkansson, and Rickard Brånemark},
  title    = {Real-Time and Simultaneous Control of Artificial Limbs Based on Pattern Recognition Algorithms},
  journal  = {IEEE},
  year     = {2014},
  volume   = {22},
  number   = {4},
  pages    = {9},
  month    = jul,
  abstract = {The prediction of simultaneous limb motions is a highly desirable feature for the control of artificial limbs. In this work, we investigate different classification strategies for individual and simultaneous movements based on pattern recognition of myoelectric signals. Our results suggest that any classifier can be potentially employed in the prediction of simultaneous movements if arranged in a distributed topology. On the other hand, classifiers inherently capable of simultaneous predictions, such as the multi-layer perceptron (MLP), were found to be more cost effective, as they can be successfully employed in their simplest form. In the prediction of individual movements, the one-vs-one (OVO) topology was found to improve classification accuracy across different classifiers and it was therefore used to benchmark the benefits of simultaneous control. As opposed to previous work reporting only offline accuracy, the classification performance and the resulting controllability are evaluated in real time using the motion test and target achievement control (TAC) test, respectively.
We propose a simultaneous classification strategy based on MLP that outperformed a top classifier for individual movements (LDA-OVO), thus improving the state-of-the-art classification approach. Furthermore, all the presented classification strategies and data collected in this study are freely available in BioPatRec, an open source platform for the development of advanced prosthetic control strategies.},
  file     = {:Artificial Intelligence/Real-Time and Simultaneous Control of Artificial.pdf:PDF},
  keywords = {Artificial limbs, artificial neural networks (ANN), mixed classes pattern recognition, prosthetic limbs, simultaneous pattern recognition},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/Real-Time%20and%20Simultaneous%20Control%20of%20Artificial.pdf},
}

@Article{BORJABORDEL2018,
  author   = {BORJA BORDEL, RAMÓN ALCARRIA, TOMÁS ROBLES, AND ÁLVARO SÁNCHEZ-PICOT},
  title    = {Stochastic and Information Theory Techniques to Reduce Large Datasets and Detect Cyberattacks in Ambient Intelligence Environments},
  journal  = {IEEE},
  year     = {2018},
  volume   = {6},
  pages    = {15},
  month    = jun,
  abstract = {Ambient intelligence refers a new technological paradigm, where everyday environments behave in a smart way and are sensitive to their inhabitants. In order to reach this objective, complex pervasive sensing platforms are deployed, together with artificial intelligence solutions. In these new, complex, and highly interdependent systems, traditional security policies and defense strategies are not effective, as thousands of heterogeneous cyber and physical elements are mixed and connected. New security solutions try to learn about the expected behavior from the system and its components, so if a strange event occurs; adequate preventive, corrective, and/or reactive security actions to detect and stop the potential cyberphysical attack being performed are triggered in an intelligent way. In order to learn about the system and select and apply the adequate security actions, very large datasets containing records of previous behaviors should be analyzed, sometimes in a very fast way. This fact enormously complicates the implementation of these new security solutions, as it is necessary a huge storage capacity, which many domestic systems do not have, and it is needed to work with huge data sets whose processing time prevents making decisions with the required speed. Therefore, in this paper, we investigate and propose a procedure to reduce large datasets, with the objective of enabling new security techniques to detect cyberattacks in a fast and efficient way. The proposed procedure is based on the calculation of small sets of samples, whose statistic configuration is as similar as desired to the original large dataset. Stochastic models and information theory techniques and theorems are composed and combined in order to define a mathematical framework which allows the obtention of these equivalent reduced datasets. We also describe and evaluate a first implementation of the proposed solution, using both, a simulation scenario and a real deployment.},
  file     = {:Artificial Intelligence/Stochastic and Information Theory Techniques to reduce cyber attacks.pdf:PDF},
  keywords = {Ambient intelligence, security, big data, cybersecurity, stochastic models, information theory.},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/Stochastic%20and%20Information%20Theory%20Techniques%20to%20reduce%20cyber%20attacks.pdf},
}

@Article{S.M.RIAZULISLAM2015,
  author   = {S. M. RIAZUL ISLAM, (Member, IEEE), DAEHAN KWAK , MD. HUMAUN KABIR, MAHMUD HOSSAIN, AND KYUNG-SUP KWAK , (Member, IEEE)},
  title    = {The Internet of Things for Health Care:,A Comprehensive Survey},
  journal  = {IEEE},
  year     = {2015},
  volume   = {3},
  pages    = {31},
  month    = jun,
  abstract = {The Internet of Things (IoT) makes smart objects the ultimate building blocks in the development of cyber-physical smart pervasive frameworks. The IoT has a variety of application domains, including health care. The IoT revolution is redesigning modern health care with promising technological, economic, and social prospects. This paper surveys advances in IoT-based health care technologies and reviews the state-of-the-art network architectures/platforms, applications, and industrial trends in IoT-based health care solutions. In addition, this paper analyzes distinct IoT security and privacy features, including security requirements, threat models, and attack taxonomies from the health care perspective. Further, this paper proposes an intelligent collaborative security model to minimize security risk; discusses how different innovations such as big data, ambient intelligence, and wearables can be leveraged in a health care context; addresses various IoT and eHealth policies and regulations across the world to determine how they can facilitate economies and societies in terms of sustainable development; and provides some avenues for future research on IoT-based health care based on a set of open issues and challenges.},
  file     = {:Artificial Intelligence/The Internet of Things for Health Care survey.pdf:PDF},
  keywords = {Internet of things, health care, services, applications, networks, architectures, platforms, security, technologies, industries, policies, challenges.},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/The%20Internet%20of%20Things%20for%20Health%20Care%20survey.pdf},
}

@Article{LINCHEN2018,
  author   = {LIN CHEN, ZHILIN QIAO , MINGGANG WANG, CHAO WANG4, RUIJIN DU, AND HARRY EUGENE STANLEY},
  title    = {Which Artificial Intelligence Algorithm Better Predicts the Chinese Stock Market?},
  journal  = {IEEE},
  year     = {2018},
  volume   = {6},
  pages    = {9},
  month    = jul,
  abstract = {Unpredictable stock market factors make it difficult to predict stock index futures. Although efforts to develop an effective prediction method have a long history, recent developments in artificial intelligence and the use of artificial neural networks have increased our success in nonlinear approximation. When we study financial markets, we can now extract features from a big data environment without prior predictive information. We here propose to further improve this predictive performance using a combination of a deep-learning-based stock index futures prediction model, an autoencoder, and a restricted Boltzmann machine. We use high-frequency data to examine the predictive performance of deep learning, and we compare three traditional artificial neural networks: 1) the back propagation neural network; 2) the extreme learning machine; and 3) the radial basis function neural network. We use all of the 1-min high-frequency transaction data of the CSI 300 futures contract (IF1704) in our empirical analysis, and we test three groups of different volume samples to validate our observations. We find that the deep learning method of predicting stock index futures outperforms the back propagation, the extreme learning machine, and the radial basis function neural network in its fitting degree and directional predictive accuracy. We also find that increasing the amount of data increases predictive performance. This indicates that deep learning captures the nonlinear features of transaction data and can serve as a powerful stock index futures prediction tool for financial market investors.},
  file     = {:Artificial Intelligence/Which Artificial Intelligence Algorithm Better.pdf:PDF},
  keywords = {S Prediction methods, artificial neural networks, stock markets, deep learning.},
  url      = {file:///C:/project/FYP%20done/RPs/Artificial%20Intelligence/Which%20Artificial%20Intelligence%20Algorithm%20Better.pdf},
}

@Article{SHANLIU2013,
  author   = {SHAN LIU, SALMAN MASHAYEKH, DEEPA KUNDUR, TAKIS ZOURNTOS, AND KAREN BUTLER-PURRY},
  title    = {A Framework for Modeling Cyber-Physical Switching Attacks in Smart Grid},
  journal  = {IEEE},
  year     = {2013},
  volume   = {1},
  number   = {2},
  pages    = {13},
  month    = dec,
  abstract = {T Security issues in cyber-physical systems are of paramount importance due to the often safetycritical nature of its associated applications. A first step in understanding how to protect such systems requires an understanding of emergent weaknesses, in part, due to the cyber-physical coupling. In this paper, we present a framework that models a class of cyber-physical switching vulnerabilities in smart grid systems. Variable structure system theory is employed to effectively characterize the cyber-physical interaction of the smart grid and demonstrate how existence of the switching vulnerability is dependent on the local structure of the power grid. We identify and demonstrate how through successful cyber intrusion and local knowledge of the grid an opponent can compute and apply a coordinated switching sequence to a circuit breaker to disrupt operation within a short interval of time. We illustrate the utility of the attack approach empirically on the Western Electricity Coordinating Council three-machine, nine-bus system under both model error and partial
state information.},
  file     = {:Cyber security/A Framework for Modeling Cyber-Physical.pdf:PDF},
  keywords = {Cyber-physical systems, security modeling, variable structure systems, coordinated switching attacks.},
  url      = {file:///C:/project/FYP%20done/RPs/Cyber%20security/A%20Framework%20for%20Modeling%20Cyber-Physical.pdf},
}

@Article{AnnaL.Buczak2015,
  author   = {Anna L. Buczak, Member, IEEE, and Erhan Guven, Member, IEEE},
  title    = {A Survey of Data Mining and Machine Learning Methods for Cyber Security Intrusion Detection},
  journal  = {IEEE},
  year     = {2015},
  volume   = {18},
  number   = {2},
  pages    = {24},
  month    = may,
  abstract = {This survey paper describes a focused literature survey of machine learning (ML) and data mining (DM) methods for cyber analytics in support of intrusion detection. Short tutorial descriptions of each ML/DM method are provided. Based on the number of citations or the relevance of an emerging method, papers representing each method were identified, read, and summarized. Because data are so important in ML/DM approaches, some well-known cyber data sets used in ML/DM are described. The complexity of ML/DM algorithms is addressed, discussion of challenges for using ML/DM for cyber security is presented, and some recommendations on when to use a given method are provided.},
  file     = {:Cyber security/A Survey of Data Mining and Machine Learning.pdf:PDF},
  keywords = {Cyber analytics, data mining, machine learning.},
  url      = {file:///C:/project/FYP%20done/RPs/Cyber%20security/A%20Survey%20of%20Data%20Mining%20and%20Machine%20Learning.pdf},
}

@Article{YUDHISTIRANUGRAHA2015,
  author   = {YUDHISTIRA NUGRAHA, (Student Member, IEEE), IAN BROWN, AND ASHWIN SASONGKO SASTROSUBROTO},
  title    = {An Adaptive Wideband Delphi Method to Study State Cyber-Defence Requirements},
  journal  = {IEEE},
  year     = {2015},
  volume   = {4},
  number   = {1},
  pages    = {13},
  month    = jan,
  abstract = {Edward Snowden’s revelations of the extensive global communications surveillance activities of foreign intelligence services have led countries such as Indonesia to take concrete steps to enhance protective information security for classified data and communications. This paper develops the wideband Delphi method to study the Indonesian Government’s requirements for cyber-defence in response to reported secret intelligence collection by the Australian Signals Directorate. It provides a clearer understanding of the issues that influence Indonesian policymakers’ views on the mitigation of foreign surveillance. We developed and conducted an adaptive wideband Delphi study with senior Indonesian officials, with group discussions and individual sessions to explore how to mitigate the surveillance activities of the Five Eyes (the  .S.–U.K.–Canada–Australia–New Zealand) intelligence alliance. We used the U.S. National Security Agency framework of the three elements of defence in depth (people, operations, and technology), in combination
with governance and legal remedies, as an analytical framework. We identified twenty-five mitigation controls to deal with the priority concerns of policymakers, which were divided into a five-defence in depth elements. We discuss the key requirements for protecting against foreign surveillance to be taken into account in state cyber-defence frameworks and suggest effective mitigation controls for safeguarding and  rotecting states’ national interests.},
  file     = {:Cyber security/An Adaptive Wideband Delphi Method to.pdf:PDF},
  keywords = {State self-defence, defence in depth, adaptive wideband Delphi, foreign surveillance, national interests, information security, requirements.},
  url      = {file:///C:/project/FYP%20done/RPs/Cyber%20security/An%20Adaptive%20Wideband%20Delphi%20Method%20to.pdf},
}

@Article{MARTINSPAN2018,
  author   = {MARTIN SPAN, III,, (Member, IEEE), LOGAN O. MAILLOUX , (Senior Member, IEEE), ROBERT F. MILLS, (Senior Member, IEEE), AND WILLIAM YOUNG, JR.,},
  title    = {Conceptual Systems Security Requirements Analysis: Aerial Refueling Case Study},
  journal  = {IEEE},
  year     = {2018},
  volume   = {6},
  pages    = {15},
  month    = aug,
  abstract = {In today’s highly interconnected and technology-reliant environment, cybersecurity is no longer limited to traditional computer systems and IT networks, as a number of highly publicized attacks have occurred against complex cyber-physical systems such as automobiles and airplanes. While numerous vulnerability analysis and architecture analysis approaches are in use, these approaches are often focused on realized systems with limited solution space. A more effective approach for understanding security and resiliency requirements early in the system development is needed. One such approach, systemtheoretic process analysis for security (STPA-Sec), addresses the cyber-physical security problem from a systems viewpoint at the conceptual stage when the solution trade-space is largest rather than merely examining components and adding protections during production, operation, or sustainment. This paper uniquely provides a detailed and independent evaluation of STPA-Sec’s utility for eliciting, defining,and understanding security and resiliency requirements for a notional next generation aerial refueling platform.},
  file     = {:Cyber security/Conceptual Systems Security Requirements.pdf:PDF},
  keywords = {Cybersecurity, requirements engineering, security, security engineering, systems engineering, systems security engineering.},
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=Conceptual+Systems+Security+Requirements+Analysis%3A+Aerial+Refueling+Case+Study&btnG=},
}

@Article{ZHIHONGTIAN2018,
  author   = {ZHIHONG TIAN, YU CUI, LUN AN, SHEN SU, XIAOXIA YIN,LIHUA YIN, AND XIANG CUI},
  title    = {A Real-Time Correlation of Host-Level Events in Cyber Range Service for Smart Campus},
  journal  = {IEEE},
  year     = {2018},
  volume   = {6},
  pages    = {10},
  month    = jun,
  abstract = {Smart campus is an exciting, new, and emerging research area that uses technology and infrastructure to support and improve its processes in campus services, teaching, learning, and research, especially, the explosive growth in knowledge makes the role of cybersecurity of smart campus become increasingly important. Cyber range is an adaptable virtualization platform consisting of computers, networks, and systems on which various real-world cyber threat scenarios and systems can be evaluated to provide a comprehensive, unbiased assessment of the security of information and automated control systems. As an important part of features, cyber range must provide the capability of data collection, aggregation, correlation, and replay for the scenario owner or any ‘‘specialized users’’ to review attacks–defense processes on known targets and future  ero-day research. To this end, based on our previous work, the Heetian cyber range, we proposed a method named C2RS meaning ‘‘a real-time correlation of host-level events in cyber range service.’’ C2RS implements out-of-band data capturing for greater attack resistance with virtual machine introspection technique. This approach allows C2RS to isolate the data captured from monitored hosts. C2RS leverages these captured data by incorporating them into the volatility framework to aid in simplifying the analysis of operating system memory structures. Finally, we proposed an object-dependent method to analyze the evidence of illegal activity. We conduct extensive experiments to evaluate the functions and performance of C2RS in a dynamic service. Through the test, we confirm that the proposed method is effective for real-time correlation of host-level events in cyber range service.},
  file     = {:Cyber security/Cyber Range Service for Smart Campus.pdf:PDF},
  keywords = {Security education, cyber range, network security, correlation, smart campus},
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=A+Real-Time+Correlation+of+Host-Level+Events+in+Cyber+Range+Service+for+Smart+Campus&btnG=},
}

@Article{IVOFRIEDBERG2017,
  author   = {IVO FRIEDBERG, XIN HONG, KIERAN MCLAUGHLIN, PAUL SMITH, AND PAUL C. MILLER},
  title    = {Evidential Network Modeling for Cyber-Physical System State Inference},
  journal  = {IEEE},
  year     = {2017},
  volume   = {5},
  pages    = {17149--17164},
  month    = jun,
  abstract = {Cyber-physical systems (CPSs) have dependability requirements that are associated with controlling a physical process. Cyber-attacks can result in those requirements not being met. Consequently, it is important to monitor a CPS in order to identify deviations from normal operation. A major challenge is inferring the cause of these deviations in a trustworthy manner. This is necessary to support the implementation of correct and timely control decisions, in order to mitigate cyber-attacks and other causes of reduced dependability. This paper presents evidential networks as a solution to this problem. Through the evaluation of a representative use case for cyber-physical control systems, this paper shows novel approaches to integrate low-level sensors of different types, in particular those for cyber-attack detection, and reliabilities into evidential networks. The results presented indicate that evidential networks can identify system states with an accuracy that is comparable to approaches that use classical Bayesian probabilities to describe causality. However, in addition, evidential networks provide information about the uncertainty of a derive  system state, which is a significant benefit, as it can be used to build trust in the results of automatic reasoning systems.},
  file     = {:Cyber security/Cyber-Physical system.pdf:PDF},
  keywords = {Communication technologies, computer networks, network security, data system, data processing, data integration, industry applications, security, security management, power engineering and energy, power systems, microgrid, attack causality},
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=Evidential+Network+Modeling+for+Cyber-Physical&btnG=},
}

@Article{RAMIREZ2016,
  author   = {ROBERT RAMIREZ AND NAZLI CHOUCRI},
  title    = {Improving Interdisciplinary Communication With Standardized Cyber Security Terminology: A Literature Review},
  journal  = {IEEE},
  year     = {2016},
  volume   = {4},
  pages    = {2216--2243},
  month    = mar,
  abstract = {The growing demand for computer security, and the cyberization trend, are hallmarks of the 21st century. The rise in cyber-crime, digital currency, and e-governance has been well met by a corresponding recent jump in investment in new technology for securing computers around the globe. Business and government sectors have begun to focus effort on comprehensive cyber security solutions. With this effort has emerged a need for greater collaboration between research and industry fields. Despite much effort, there is still too little cross-disciplinary collaboration in the realm of computer security. This paper reviews the new trends, contributions, and identifiable limitations in cyber security research. We argue that these limitations are due largely to the lack of interdisciplinary cooperation required to address a problem that is clearly multifaceted. We then identify a need for further refinement of standard cyber security terminology to facilitate interdisciplinary cooperation, and propose guidelines for the global Internet multistakeholder community to consider when crafting such standards. We also assess the viability of some specific jargon, including whether cyber should be a separate word when used as a descriptor (e.g. cybercrime or cybercrime), and conclude with recommendations for terminology use when writing papers on cyber security or the new broader field of all things relating to cyberspace, which has recently been dubbed Cybermatics, a term we also examine and propose alternatives to. By furthering the effort to standardize cyber security terminology, this paper lays groundwork for cross-disciplinary collaboration, interaction between technical and nontechnical stakeholders, and drafting of universal Internet governance laws.},
  file     = {:Cyber security/Improving Interdisciplinary Communication With Cyber security.pdf:PDF},
  keywords = {Cyber security, cyber-crime, cybersecurity, internet, hacker, national security, critical infrastructure, cyberspace, information technology, ICT, dictionaries, standardization, standards.},
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=Improving+Interdisciplinary+Communication+With+Standardized+Cyber+Security+Terminology%3A&btnG=},
}

@Article{MISCHAMOeSTL2018,
  author   = {y MISCHA MÖSTL , JOHANNES SCHLATOW, ROLF ERNST, NIKIL DUTT, AHMED NASSAR, AMIR RAHMANI, FADI J. KURDAHI, THOMAS WILD, ARMIN SADIGHI, AND ANDREAS HERKERSDORF},
  title    = {Platform-Centric Self-Awareness as a Key Enabler for Controlling Changes in CPS},
  journal  = {IEEEE},
  year     = {2018},
  volume   = {106},
  number   = {9},
  pages    = {1543--1567},
  month    = sep,
  abstract = {| Future cyber–physical systems will host a large number of coexisting distributed applications on hardware platforms with thousands to millions of networked components communicating over open networks. These applications and networks are subject to continuous change. The current separation of design process and operation in the field will be superseded by a life-long design process of adaptation, infield integration, and update. Continuous change and evolution, application interference, environment dynamics and uncertainty lead to complex effects which must be controlled to serve a growing set of platform and application needs.
Self-adaptation based on self-awareness and self-configuration has been proposed as a basis for such a continuous in-field process. Research is needed to develop automated in-field design methods and tools with the required safety, availability, and security guarantees. The paper shows two complementary use cases of self-awareness in architectures, methods, and tools for cyber–physical systems. The first use case focuses
on safety and availability guarantees in self-aware vehicle platforms. It combines contracting mechanisms, tool based self-analysis and self-configuration. A software architecture and a runtime environment executing these tools and mechanisms autonomously are presented including aspects of selfprotection against failures and security threats. The second use case addresses variability and long term evolution in networked MPSoC integrating hardware and software mechanisms of surveillance, monitoring, and continuous adaptation. The approach resembles the logistics and operation principles of manufacturing plants which gave rise to the metaphoric term of an Information Processing Factory that relies on incremental changes and feedback control. Both use cases are investigated by larger research groups. Despite their different approaches, both use cases face similar design and design automation challenges which will be summarized in the end. We will argue that seemingly unrelated research challenges, such as in machine learning and security, could also profit from the methods and superior modeling capabilities of self-aware systems.},
  file     = {:Cyber security/Platform-Centric CPS.pdf:PDF},
  keywords = {Cyber-physical systems; design automation; embedded systems; self-awareness},
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=Platform-Centric+Self-Awareness+as+a+Key+Enabler+for+Controlling+Changes+in+CPS&btnG=},
}

@Article{Ge2018,
  author   = {Hui Ge and Zhenjiang Zhao},
  title    = {Security Analysis of Energy Internet With Robust Control Approaches and Defense Design},
  journal  = {IEEE},
  year     = {2018},
  volume   = {6},
  pages    = {11203--11214},
  month    = feb,
  abstract = {Power cyber-physical systems (PCPSs) are becoming increasingly complex and diverse, benefitting from all aspects of societal issues. A PCPS is a next-generation system that is a tight conjunction of computation, communication, control, and power systems. The integration of Internet of Things and PCPS generates a novel energy system, the Internet of Energy, which is the future of the energy system. In the same way, the connection of bulk components and the extensive communications among them has brought many insecurities, uncertainties, and security challenges. Thus, a study of the analysis and synthesis of the reliability and security of PCPS is presented in this paper. By considering the unsafe uncertainties, models are formulated for a general cyber-attack, and a double-loop architecture for security defense is designed. According to this framework, security control scenarios are obtained from the character of each kind of cyber-attack. Finally, a separately excited dc motor with uncertainty is used as an example to demonstrate the problem.},
  file     = {:Cyber security/Security Analysis of Energy Internet With Robust.pdf:PDF},
  keywords = {Energy Internet, Internet of Things, power cyber-physical system, cyber security, system uncertainty},
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=Security+Analysis+of+Energy+Internet+With+Robust+Control+Approaches+and+Defense+Design&btnG=},
}

@Article{LU-XINGYANG2017,
  author   = {LU-XING YANG, (Member, IEEE), PENGDENG LI, XIAOFAN YANG, (Member, IEEE), AND YUAN YAN TANG, (Fellow, IEEE)},
  title    = {Security Evaluation of the Cyber Networks Under Advanced Persistent Threats},
  journal  = {IEEE},
  year     = {2017},
  volume   = {5},
  pages    = {20111--20123},
  month    = sep,
  abstract = {Advanced persistent threats (APTs) pose a grave threat to cyberspace, because they deactivate all the conventional cyber defense mechanisms. This paper addresses the issue of evaluating the security of the cyber networks under APTs. For this purpose, a dynamic model capturing the APT-based cyberattack-defense processes is proposed. Theoretical analysis shows that this model admits a globally stable equilibrium. On this basis, a new security metric known as the equilibrium security is suggested. The impact of several factors on the equilibrium security is revealed through theoretical analysis or computer simulation. These findings contribute to the development of feasible security solutions against APTs.},
  file     = {:Cyber security/Security Evaluation of the Cyber Networks.pdf:PDF},
  keywords = {Cyberspace, security, measurement, nonlinear dynamical systems, stability},
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=Security+Evaluation+of+the+Cyber+Networks+Under+Advanced+Persistent+Threats&btnG=},
}

@Article{ALTAWY2016,
  author   = {RIHAM ALTAWY AND AMR M. YOUSSEF, (Senior Member, IEEE)},
  title    = {Security Tradeoffs in Cyber Physical Systems: A Case Study Survey on Implantable Medical Devices},
  journal  = {IEEE},
  year     = {2016},
  volume   = {4},
  pages    = {959--979},
  month    = jan,
  abstract = {The new culture of networked systems that offer everywhere accessible services has given rise to various types of security tradeoffs. In fact, with the evolution of physical systems that keep getting integrated with cyber frameworks, cyber threats have far more critical effects as they get reflected on the physical environment. As a result, the issue of security of cyber physical systems requires a special holistic treatment. In this paper, we study the tradeoff between security, safety, and availability in such systems and demonstrate these concepts on implantable medical devices as a case study. We discuss the challenges and constraints associated with securing such systems and focus on the tradeoff between security measures required for blocking unauthorized access to the device and the safety of the patient in emergency situations where such measures must be dropped to allow access. We analyze the up to date proposed solutions and discuss their strengths and limitations.},
  file     = {:Cyber security/Security Tradeoffs in Cyber Physical Systems.pdf:PDF},
  keywords = {Access control, cyber physical systems, implantable medical devices, security vs. safety.},
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=Security+Tradeoffs+in+Cyber+Physical+Systems%3A+A+Case+Study+Survey+on+Implantable+Medical+Devices&btnG=},
}

@Article{STEPHENKHOU2017,
  author   = {STEPHEN KHOU, LOGAN O. MAILLOUX, (Member, IEEE), AND JOHN M. PECARINA},
  title    = {System-agnostic security domains for understanding and prioritizing systems security engineering efforts},
  journal  = {IEEE},
  year     = {2017},
  volume   = {5},
  pages    = {3465--3474},
  month    = mar,
  abstract = {As modern systems continue to increase in size and complexity, current systems security practices lack an effective approach to prioritize and tailor systems security efforts to successfully develop and field systems in challenging operational environments. This paper uniquely proposes seven systemagnostic security domains, which assist in understanding and prioritizing systems security engineering (SSE) efforts. To familiarize the reader with the state-of-the-art in SSE practices, we first provide a comprehensive discussion of foundational SSE concepts, methodologies, and frameworks. Next, the seven system-agnostic security domains are presented for consideration by researchers and practitioners. The domains are intended to be representative of a holistic SSE approach, which is universally applicable to multiple systems classes and not just a single-system implementation. Finally, three examples are explored to illustrate the utility of the system-agnostic domains for understanding and prioritizing SSE efforts in information technology systems, Department of Defense weapon systems, and cyber-physical systems.},
  file     = {:Cyber security/System-Agnostic Security Domains for Security.pdf:PDF},
  keywords = {Security domains, systems security engineering, systems engineering, security engineering.},
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=System-Agnostic+Security+Domains+for+Understanding+and+Prioritizing+Systems+Security+Engineering+Effor&btnG=},
}

@Article{Rahman2017,
  author   = {Rahman, Syed Sadiqur and Heartfield, Ryan and Oliff, William and Loukas, George and Filippoupolitis, Avgoustinos},
  title    = {Assessing the cyber-trustworthiness of human-as-a-sensor reports from mobile devices},
  journal  = {IEEE},
  year     = {2017},
  pages    = {387--394},
  month    = jun,
  file     = {:Cyber security/Trustworthiness of human report from mobile devices.pdf:PDF},
  keywords = {human-as-a-sensor, information trustworthliness, cyber security, provenance of information, mobile security, location spoofing},
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=accessing+the+cyber-trustworthiness+of+human-as-a-sensor+reports+from+mobilr+device&btnG=},
}

@Article{Sabar2016,
  author   = {Sabar, Nasser R and Yi, Xun and Song, And},
  title    = {A Bi-objective Hyper-Heuristic Support Vector Machines for Big Data Cyber-Security},
  journal  = {IEEE},
  year     = {2016},
  volume   = {6},
  pages    = {10421--10431},
  month    = mar,
  abstract = {Cyber security in the context of big data is known to be a critical problem and presents a great challenge to the research community. Machine learning algorithms have been suggested as candidates for handling big data security problems. Among these algorithms, support vector machines (SVMs) have achieved remarkable success on various classification problems. However, to establish an effective SVM, the user needs to  efine the proper SVM configuration in advance, which is a challenging task that requires expert knowledge and a large amount of manual effort for trial and error. In this paper, we formulate the SVM configuration process as a bi-objective optimization problem in which accuracy and model complexity are considered as two conflicting objectives. We propose a novel hyper-heuristic framework for bi-objective optimization that is  ndependent of the problem domain. This is the first time that a hyper-heuristic has been developed for this problem. The proposed hyper-heuristic framework consists of a high-level strategy and low-level heuristics. The high-level strategy uses the search performance to control the selection of which low-level heuristic should be used to generate a new SVM configuration. The low-level heuristics each use different rules to effectively explore the SVM configuration search space. To address bi-objective optimization, the proposed framework adaptively integrates the strengths of decomposition- and Paretobased approaches to approximate the Pareto set of SVM configurations. The effectiveness of the proposed framework has been evaluated on two cyber security problems: Microsoft malware big data classification and anomaly intrusion detection. The obtained results demonstrate that the proposed framework is very effective, if not superior, compared with its counterparts and other algorithms.},
  file     = {:Cyber security/Vector MaChine for big data cyber security.pdf:PDF},
  keywords = {Hyper-heuristics, big data, cyber security, optimisation.},
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=A+Bi-objective+Hyper-Heuristic+Support+Vector+Machines+for+Big+Data+Cyber-Security&btnG=},
}

@Article{Xu2014,
  author   = {Xu, Lei and Jiang, Chunxiao and Wang, Jian and Yuan, Jian and Ren, Yong},
  title    = {Information security in big data: privacy and data mining},
  journal  = {IEEE},
  year     = {2014},
  volume   = {2},
  pages    = {1149--1176},
  month    = oct,
  abstract = {The growing popularity and development of data mining technologies bring serious threat to the security of individual’s sensitive information. An emerging research topic in data mining, known as privacypreserving
data mining (PPDM), has been extensively studied in recent years. The basic idea of PPDM is to modify the data in such a way so as to perform data mining algorithms effectively without compromising the security of sensitive information contained in the data. Current studies of PPDM mainly focus on how to reduce the privacy risk brought by data mining operations, while in fact, unwanted disclosure of sensitive information may also happen in the process of data collecting, data publishing, and information (i.e., the data mining results) delivering. In this paper, we view the privacy issues related to data mining from a wider perspective and investigate various approaches that can help to protect sensitive information. In particular, we identify four different types of users involved in data mining applications, namely, data provider, data collector, data miner, and decision maker. For each type of user, we discuss his privacy concerns and the methods that can be adopted to protect sensitive information. We briefly introduce the basics of related research topics, review state-of-the-art approaches, and present some preliminary thoughts on future research directions. Besides exploring the privacy-preserving approaches for each type of user, we also review the game theoretical approaches, which are proposed for analyzing the interactions among different users in a data mining scenario, each of whom has his own valuation on the sensitive information. By differentiating the ,responsibilities of different users with respect to security of sensitive information, we would like to provide some useful insights into the study of PPDM.},
  file     = {:Cryptography/06919256.pdf:PDF},
  keywords = {Data mining, sensitive information, privacy-preserving data mining, anonymization, provenance, game theory, privacy auction, anti-tracking.},
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=Information+security+in+big+data%3A+privacy+and+data+mining&btnG=},
}

@Article{Fabry2014,
  author   = {Fabry, Johan and Robbes, Romain and Denker, Marcus},
  title    = {DIE: A Domain Specific Aspect Language for IDE Events},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {2},
  pages    = {34},
  month    = feb,
  abstract = {Integrated development environments (IDEs) have become the primary way to develop software. Besides just using the built-in features, it becomes more and more important to be able to extend the IDE with new features and  extensions. Plugin architectures exist, but they show weaknesses related to unanticipated extensions and event handling. In this paper, we argue that a more general solution for extending IDEs is needed. We present and discuss a solution, motivated by a set of concrete examples: a domain specific aspect language for IDE events. In it, join points are events of interest that may trigger the advice in which the behavior of the IDE extension is called. We show how this allows for the development of IDE plugins and demonstrate the advantages over traditional publish/subscribe systems.},
  file     = {:done rp/1.pdf:PDF},
  keywords = {IDE, Plugins, Development Environment, Domain Specific Aspect Languages, Aspects},
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=DIE%3A+A+Domain+Specific+Aspect+Language+for+IDE+Events&btnG=},
}

@Article{IsraelGutierrez-Rojas2014,
  author   = {Israel Gutiérrez-Rojas, Raquel M. Crespo-García and Carlos Delgado Kloos},
  title    = {Adapting an Awareness Tool for Massive Courses: the Case of ClassON},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {1},
  pages    = {15},
  month    = jan,
  abstract = { In this paper we analyse the challenges posed to teachers and students in massive face-to-face classes and explore how existing solutions can be applied to these contexts. In particular, we focus on classON1, a tool that provides teachers and students with the appropriate information to make the most out of face-to-face sessions in the computer lab. classON has been well tested in small-medium face-to-face lab sessions and we discuss some of its
characteristics (current ones and foreseen) to adapt it to massive courses. As a result, we provide a set of recommendations for adapting tools to support massive face-to-face learning activities.},
  file     = {:done rp/2.pdf:PDF},
  keywords = {teacher awareness, massive learning environments, face-to-face teaching, just-intime teaching, scalability, active learning},
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=Adapting+an+Awareness+Tool+for+Massive+Courses%3A+the+Case+of+ClassON&btnG=},
}

@Article{Blanco2014,
  author   = {Blanco, Carlos and de Guzm{\'a}n, Ignacio Garc{\'\i}a Rodr{\'\i}guez and Fern{\'a}ndez-Medina, Eduardo and Trujillo, Juan},
  title    = {Showing the Benefits of Applying a Model Driven Architecture for Developing Secure OLAP Applications},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {2},
  pages    = {79--106},
  month    = jan,
  abstract = { Data Warehouses (DW) manage enterprise information that is queried for decision making purposes by using On-Line Analytical Processing (OLAP) tools. The establishment of security constraints in all development stages and operations of the DW is highly important since otherwise, unauthorized users may discover vital business information. The final users of OLAP tools access and analyze the information from the corporate DW by using specific views or cubes based on the multidimensional modelling containing the facts and dimensions (with the corresponding classification hierarchies) that a decision maker or group of
decision makers are interested in. Thus, it is important that security constraints will be also
established over this metadata layer that connects the DW’s repository with the decision
makers, that is, directly over the multidimensional structures that final users manage. In doing
so, we will not have to define specific security constraints for every particular user, thereby
reducing the developing time and costs for secure OLAP applications.
In order to achieve this goal, a model driven architecture to automatically develop secure
OLAP applications from models has been defined. This paper shows the benefits of this
architecture by applying it to a case study in which an OLAP application for an airport DW is
automatically developed from models. The architecture is composed of: (1) the secure
conceptual modelling by using a UML profile; (2) the secure logical modelling for OLAP
applications by using an extension of CWM; (3) the secure implementation into a specific
OLAP tool, SQL Server Analysis Services (SSAS); and (4) the transformations needed to
automatically generate logical models from conceptual models and the final secure
implementation},
  file     = {:done rp/5.pdf:PDF},
  keywords = {Security, Confidentiality, OLAP, Data Warehouses, Model Driven, MDA, Transformations, SSAS, Case Study.},
  url      = {file:///C:/Users/khiyra009gmail.com/Documents/project/FYP%20done/database/done%20rp/5.pdf},
}

@Article{Chenaina2014,
  author   = {Chenaina, Tarek and Alraddadi, Abdulaziz},
  title    = {Identifying Fuzzy Controllers Parameters by Fuzzy Clustering Technique},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {2},
  pages    = {107--134},
  month    = feb,
  abstract = { In fuzzy control, there is a large amount of parameters involved in the system design.
Due to their interdependency, these parameters are sometimes conflicting causing an
unavoidable trade-off among performance indices. It is difficult to discern the best combination
of fuzzy parameters with respect to a given range of some performance indices. In this case, a
clustering technique represents a powerful tool to deal with the problem. Main clusters of fuzzy
controllers having similar behavior with respect to some performance indices are discovered. In
order to precisely characterize rule bases and transform them to a quantifiable entity, transition
between topological and numerical form of fuzzy rule bases is studied. Formulating a vector
space structure and a base of relationships between fuzzy sets represents one of the main foci of
the research. Adding logic parameters and defuzzification procedures to the formulated vectors
is required to apply the clustering technique. In fact, this latter requires the existence of
quantifiable fuzzy controllers. The obtained vectors are then treated by a fuzzy-neural
clustering algorithm. Membership nuance to a cluster allows better legibility to evaluate
relevance and relative interest of fuzzy controller parameters according to performance indices.},
  file     = {:done rp/6.pdf:PDF},
  keywords = { Fuzzy logic, Fuzzy Logic Controllers, Vector Space, Classes of Fuzzy Controllers, Clustering and Learning },
  url      = {file:///C:/Users/khiyra009gmail.com/Documents/project/FYP%20done/database/done%20rp/6.pdf},
}

@Article{Bry2014,
  author  = {Bry, Fran{\c{c}}ois and Ebner, Martin and Pohl, Alexander and Taraghi, Behnam},
  title   = {Interaction in Massive Courses J.UCS Special Issue},
  journal = {J.UCS},
  year    = {2014},
  volume  = {20},
  number  = {1},
  pages   = {1--5},
  month   = jan,
  file    = {:done rp/7.pdf:PDF},
  url     = {http://www.jucs.org/jucs_20_1/interaction_in_massive_courses/jucs_20_01_0001_0005_editorial.pdf},
}

@Article{Perez-Gonzalez2014,
  author   = {Daniel Perez-Gonzalez, Pedro Soto-Acosta,Simona Popa},
  title    = {A Virtual Campus for E-learning Inclusion: The Case of SVC-G9},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {2},
  pages    = {240--253},
  month    = jan,
  abstract = {Academics and professionals agree that, to adapt higher education institutions to the
XXI century, it is imperative to extend the use of ICT as well as the virtualization of many
human-interaction activities. There is therefore a need to move from the use of ICT as support
tools to e-learning instruments based on virtual environments. These environments can be used
for e-inclusion. That is, systems can be used to remove communication and interaction barriers
that people with disabilities may face in the real world. This paper presents a project which
implies the implementation of a virtual interuniversity campus where nine Spanish higher
education institutions took part. To enhance Web accessibility as the usability of the system by
users with disabilities is one of the main project’s objectives. In addition, the paper analyses the
teen-year experience of an e-business course for engineers offered simultaneously by the nine
universities through this platform. The main conclusions of this work can be valuable to higher
education institutions which have implemented or intend to implement a virtual interuniversity
campus. },
  file     = {:done rp/8.pdf:PDF},
  keywords = {E-learning, e-inclusion, accessibility, higher education, usability, teaching innovation },
  url      = {http://www.jucs.org/jucs_20_2/a_virtual_campus_for/jucs_20_02_0240_0253_gonzalez.pdf},
}

@Article{Ferrarotti2014,
  author  = {Ferrarotti, Flavio and Grossmann, Georg and Schewe, Klaus-Dieter and Wang, Qing},
  title   = {Conceptual Modelling with Specific Focus on Service-Oriented Systems J.UCS Special Issue},
  journal = {J.UCS},
  year    = {2014},
  volume  = {20},
  number  = {3},
  pages   = {254--256},
  month   = mar,
  file    = {:done rp/9.pdf:PDF},
  url     = {http://jucs.org/jucs_20_3/conceptual_modelling_with_specific/jucs_20_03_0254_0256_editorial.pdf},
}

@Article{Grigalis2014,
  author   = {Grigalis, Tomas and {\v{C}}enys, Antanas},
  title    = {Unsupervised Structured Data Extraction from Template-generated Web Pages},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {3},
  pages    = {169--192},
  month    = feb,
  abstract = {This paper studies structured data extraction from template-generated Web pages.
Such pages contain most of structured data on the Web. Extracted structured data can be later
integrated and reused in very big range of applications, such as price comparison portals,
business intelligence tools, various mashups and etc. It encourages industry and academics to
seek automatic solutions. To tackle the problem of automatic structured Web data extraction we
present a new approach – structured data extraction based on clustering visually similar Web
page elements. Our method called ClustVX combines visual and pure HTML features of Web
page to cluster visually similar Web page elements and then extract structured Web data.
ClustVX can extract structured data from Web pages where more than one data record is
present. With extensive experimental evaluation on three benchmark datasets we demonstrate
that ClustVX achieves better results than other state-of-the-art automatic structured Web data
extraction methods. },
  file     = {:done rp/10.pdf:PDF},
  keywords = {data extraction, wrapper induction, structured web data, Deep Web},
  url      = {http://jucs.org/jucs_20_2/unsupervised_structured_data_extraction/jucs_20_02_0169_0192_grigalis.pdf},
}

@Article{Alario-Hoyos2018,
  author   = {Carlos Alario-Hoyos, Iria Estévez-Ayres, Jesús M. Gallego-Romero, Carlos Delgado Kloos, Carmen Fernández-Panadero, Raquel M. Crespo-García, Florina Almenares, María Blanca Ibáñez, Julio Villena-Román},
  title    = {A Study of Learning-by-Doing in MOOCs through the Integration of Third-Party External Tools: Comparison of Synchronous and Asynchronous Running Modes},
  journal  = {J.UCS},
  year     = {2018},
  volume   = {24},
  number   = {8},
  pages    = {1015--1033},
  month    = aug,
  abstract = {Many MOOCs are being designed replicating traditional passive teaching
approaches but using video lectures as the means of transmitting information. However, it is
well known that learning-by-doing increases retention rates and, thus, allows achieving a more
effective learning. To this end, it is worth exploring which tools fit best in the context of each
MOOC to enrich learners’ experience, including built-in tools already available in the MOOC
platform, and third-party external tools which can be integrated in the MOOC platform. This
paper presents an example of the integration of a software development tool, called Codeboard,
in three MOOCs which serve as an introduction to programming with Java. We analyze the
effect this tool has on learners’ interaction and engagement when running the MOOCs in
synchronous (instructor-paced) or asynchronous (self-paced) modes. Results show that the
overall use of the tool is similar, regardless of the course running mode, although in the case of
the synchronous mode the use of the tool is concentrated in a shorter period of time. Results
also show that in the synchronous mode there is a higher percentage of accesses to the tool
from registered learners (who can save their advances and continue the work later); this finding
suggests that learners in the synchronous running mode are more engaged with the MOOC.},
  file     = {:done rp/11.pdf:PDF},
  keywords = {MOOCs, programming, tools, Codeboard, instructor-paced, self-paced },
  url      = {http://www.jucs.org/jucs_24_8/a_study_of_learning/jucs_24_08_1015_1033_hoyos.pdf},
}

@Article{Wautelet2018,
  author   = {Wautelet, Yves and Kolp, Manuel and Penserini, Loris},
  title    = {Service-Driven Iterative Software Project Management with I-Tropos},
  journal  = {J.UCS},
  year     = {2018},
  volume   = {24},
  number   = {7},
  pages    = {975--1011},
  month    = jul,
  abstract = {The increased symbiotic relationships between society and Information and
Communication Technology (ICT) pave the ways for a substantial alignment and rethinking of current software development methodologies. This paper presents the use
and validation of a software analysis and project management (PM) framework for
iterative software development within the Tropos method. This methodology is servicedriven, its requirements models are founded on social-based modeling elements. The
PM framework includes risk and quality management; it has been applied on multiple
case studies and this paper presents a full experience report. The proposed methodology
is aimed to provide a reference for practitioners willing to develop iteratively using
Tropos},
  file     = {:done rp/12.pdf:PDF},
  keywords = {: Service-oriented Development, Iterative Development, Software Life Cycle Management, Tropos, Unified Process, Project Management, Service Modeling},
  url      = {http://jucs.org/jucs_24_7/service_driven_iterative_software/jucs_24_07_0975_1011_wautelet.pdf},
}

@Article{MoreiraTeixeira2018,
  author  = {Rocael Hernández Rizzardini,António Moreira Teixeira, Carlos Alario-Hoyos , Héctor R. Amado-Salvatierra},
  title   = {New Trends in Massive Open Online Courses (MOOCs) J.UCS Special Issue},
  journal = {J.UCS},
  year    = {2018},
  volume  = {24},
  number  = {8},
  pages   = {1012--1014},
  month   = jul,
  file    = {:done rp/13.pdf:PDF},
  url     = {http://www.jucs.org/jucs_24_8/new_trends_in_massive/jucs_24_08_1012_1014_editorial.pdf},
}

@Article{Amarasinghe2018,
  author   = {Ishari Amarasinghe, Davinia Hernández-Leo, Kalpani Manathunga Anders Jonsson},
  title    = {Sustaining continuous collaborative learning flows in MOOCs: orchestration agent approach},
  journal  = {J.UCS},
  year     = {2018},
  volume   = {24},
  number   = {8},
  pages    = {1034-51},
  month    = aug,
  abstract = {: Collaborative learning spaces deployed in Massive Open Online Courses (MOOCs)
provide productive social learning opportunities. However, sustaining collaboration in these
spaces is challenging. This paper provides a classification of MOOCs participants based on
their behavior in a structured collaborative learning space. This analysis leads to requirements
for new technological interventions to orchestrate collaborative learning flows in MOOCs. The
paper proposes the design of an intelligent agent to address these requirements and reports a
study which shows that the intervention of the proposed orchestration agent in a MOOC
facilitates to maintain continuous yet meaningful collaboration learning flows. },
  file     = {:done rp/14.pdf:PDF},
  keywords = {: Computer-Supported Collaborative Learning (CSCL), Intelligent Agents, Massive Open Online Courses (MOOCs), Collaborative Learning Flow Patterns (CLFPs) },
  url      = {http://www.jucs.org/jucs_24_8/sustaining_continuous_collaborative_learning/jucs_24_08_1034_1051_amarasinghe.pdf},
}

@Article{G-omez-S-anchez2018,
  author   = {Miguel L. Bote-Lorenzo. Eduardo G-omez-S-anchez},
  title    = {An Approach to Build in situ Models for the Prediction of the Decrease of Academic Engagement Indicators in Massive Open Online Courses},
  journal  = {J.UCS},
  year     = {2018},
  volume   = {24},
  number   = {8},
  pages    = {1052--1071},
  month    = aug,
  abstract = {: The early detection of learners who are expected to disengage with typical
MOOC tasks such as watching lecture videos or submitting assignments is necessary to
enable timely interventions aimed at preventing it. This can be done by predicting the
decrease of academic engagement indicators that can be derived for different MOOC
tasks and computed for each learner. A posteriori prediction models can yield a good
performance but cannot be built using the information that is available in an ongoing
course at the moment the predictions are required. This paper proposes an approach to
build in situ prediction models using such information. Models were derived following
both approaches and employed to predict the decrease of three indicators that quantify
the engagement of learners with the main tasks typically proposed in a MOOC: watching lectures, solving finger exercises, and submitting assignments. The results show
that in situ models yielded a good performance for the prediction of all engagement
indicators, thus showing the feasibility of the proposed approach. This performance
was very similar to that of a posteriori models, which have the clear disadvantage that
they cannot be used to make predictions in an ongoing course based on its data.},
  file     = {:done rp/15.pdf:PDF},
  keywords = {MOOC, engagement, supervised machine learning},
  url      = {http://jucs.org/jucs_24_8/an_approach_to_build/jucs_24_08_1052_1071_lorenzo.pdf},
}

@Article{Frixione2014,
  author   = {Frixione, Marcello and Lieto, Antonio and others},
  title    = {Towards an Extended Model of Conceptual Representations in Formal Ontologies: A Typicality-Based Proposal},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {3},
  pages    = {257--276},
  month    = mar,
  abstract = {: In this paper we propose a possible solution for the problem of the computational
representation of non-classical concepts (i.e. concepts that cannot be characterized in terms of
necessary and sufficient conditions) in the field of formal ontologies. In particular, taking into
account empirical evidences coming from cognitive psychology, according to which concept
representation is not a unitary phenomenon, we suggest that a similar approach to the
representation of conceptual knowledge could be useful also in the field of ontology based
technologies. Finally we propose, in a linked open data perspective, conceptual spaces as a
suitable framework for developing some aspects of the presented proposal. },
  file     = {:done rp/16.pdf:PDF},
  keywords = {Concept Representation, Formal Ontologies, Concepts Theories, Conceptual Spaces, Prototypes, Hybrid Conceptual Representation },
  url      = {http://www.jucs.org/jucs_20_3/towards_an_extended_model/jucs_20_03_0257_0276_frixione.pdf},
}

@Article{Kl-imek2014,
  author   = {Jakub Kl´ımek, Sobˇeslav Benda, Martin Neˇcask´y},
  title    = {Translation of Structural Constraints from Conceptual Model for XML to Schematron},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {3},
  pages    = {277--301},
  month    = mar,
  abstract = {Today, XML (eXtensible Markup Language) is a standard for exchange
inside and among IT infrastructures. For the exchange to work an XML format must
be negotiated between the communicating parties. The format is often expressed as
an XML schema. In our previous work, we introduced a conceptual model for XML,
which utilizes modeling, evolution and maintenance of a set of XML schemas and allows schema designers to export modeled formats into grammar-based XML schema
languages like DTD and XML Schema. However, there is another type of XML schema
languages called rule-based languages with Schematron as their main representative. In
our preceding conference paper [Benda et al.(2013)] we briefly introduced the process
of translation from our conceptual model to Schematron. Expressing XML schemas
in Schematron has advantages over grammar-based languages and in this paper, we
describe the previously introduced translation in more detail with focus on structural
constraints and how they are represented in Schematron. Also, we discuss the possibilities and limitations of translation from our grammar-based conceptual model to the
rule-based Schematron.},
  file     = {:done rp/17.pdf:PDF},
  keywords = {XML schema, conceptual modeling, Schematron, translation},
  url      = {http://jucs.org/jucs_20_3/translation_of_structural_constraints/jucs_20_03_0277_0301_klimek.pdf},
}

@Article{Ma2014,
  author   = {Ma, Shang-Pin and Yeh, Ching-Lung and Chen, Ping-Chang},
  title    = {Service Composition Management: A Risk-Driven Approach},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {3},
  pages    = {302--328},
  month    = mar,
  abstract = {How to effectively and efficiently monitor, manage, and adapt web services
in a composite service or a service-oriented application is becoming a significant issue.
In this paper, we argue that it is insufficient to only solve emerging service faults at
the deployment time or runtime; instead, we propose that the prediction of service
faults is equally important. We devised a risk-driven service composition management
(RDSCM) approach including four main phases: (1) preparation, (2) planning, (3)
monitoring and reaction, and (4) analysis. By applying the proposed approach, risky
component services can be removed earlier, and the fault source can be tracked and
identified more easily when a fault occurs. We developed a prototype to realize the
proposed approach, and conducted experiments to verify the approach. The implementation and experiments demonstrate that the proposed risk-driven approach can
effectively and efficiently ensure the robustness of a service-oriented system.
Key Words: service management, risk management, service composition},
  file     = {:done rp/18.pdf:PDF},
  keywords = {service management, risk management, service composition},
  url      = {http://jucs.org/jucs_20_3/service_composition_management_a/jucs_20_03_0302_0328_ma.pdf},
}

@Article{Hasan2014,
  author   = {Hasan, Osman and Khayam, Syed Ali},
  title    = {Towards Formal Linear Cryptanalysis using HOL4},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {2},
  pages    = {193--212},
  month    = feb,
  abstract = {Linear cryptanalysis (LC), first introduced by Matsui, is one of the most
widely used techniques for judging the security of symmetric-key cryptosystems. Traditionally, LC is performed using computer programs that are based on some fundamental
probabilistic algorithms and lemmas, which have been validated using paper-and-pencil
proof methods. In order to raise the confidence level of LC results, we propose to formally verify its foundational probabilistic algorithms and lemmas in the higher-orderlogic theorem prover HOL4. This kind of infrastructure would also facilitate reasoning
about LC properties within the HOL4 theorem prover. As a first step towards the
proposed direction, this paper presents the formalization of two foundations of LC,
which were initially proposed in Matsui’s seminal paper. Firstly, we formally verify
the Piling-up Lemma, which allows us to compute the probability of a block cipher’s
linear approximation, given the probabilities of linear approximations of its individual
modules. Secondly, we provide a formal probabilistic analysis of Matsui’s algorithm
for deciphering information about the unknown bits of a cipher key. In order to illustrate the practical effectiveness and utilization of our formalization, we formally reason
about a couple of LC properties},
  file     = {:done rp/19.pdf:PDF},
  keywords = {Formal Verification, Higher-order logic, Probability Theory, Cryptography, Theorem Proving.},
  url      = {http://jucs.org/jucs_20_2/towards_formal_linear_cryptanalysis/jucs_20_02_0193_0212_hasan.pdf},
}

@Article{Parapar2014,
  author   = {Parapar, Javier and Losada, David E and Barreiro, Alvaro},
  title    = {Combining Psycho-linguistic, Content-based and Chat-based Features to Detect Predation in Chatrooms},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {2},
  pages    = {213--239},
  month    = feb,
  abstract = {The Digital Age has brought great benefits for the human race but also some drawbacks. Nowadays, people from opposite corners of the World can communicate online via instant
messaging services. Unfortunately, this has introduced new kinds of crime. Sexual predators have
adapted their predatory strategies to these platforms and, usually, the target victims are kids. The
authorities cannot manually track all threats because massive amounts of online conversations
take place in a daily basis. Automatic methods for alerting about these crimes need to be designed. This is the main motivation of this paper, where we present a Machine Learning approach
to identify suspicious subjects in chat-rooms. We propose novel types of features for representing the chatters and we evaluate different classifiers against the largest benchmark available.
This empirical validation shows that our approach is promising for the identification of predatory
behaviour. Furthermore, we carefully analyse the characteristics of the learnt classifiers. This
preliminary analysis is a first step towards profiling the behaviour of the sexual predators when
chatting on the Internet.},
  file     = {:done rp/20.pdf:PDF},
  keywords = {Sexual predation, Cybercrime, Text Mining, Machine Learning, Support Vector Machines, Psycho-linguistic analysis},
  url      = {http://jucs.org/jucs_20_2/combining_psycho_linguistic_content/jucs_20_02_0213_0239_parapar.pdf},
}

@Article{Rady2014,
  author   = {Rady, Mariam},
  title    = {Generating an Excerpt of a Service Level Agreement from a Formal Definition of Non-Functional Aspects Using OWL},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {3},
  pages    = {Rady, Mariam},
  month    = mar,
  abstract = {If we take a look at current cloud computing services, the only quality guarantee they provide are vague Service Level Agreements(SLA). In this paper we modelled
some non-functional aspects in an ontology and used this ontology as a knowledge base
to generate an excerpt from a service contract. We concentrate in this excerpt on availability as it is one of the most discussed attributes in current Service Level Agreements.},
  file     = {:done rp/21.pdf:PDF},
  keywords = {QoS, SLA, Contracting, Non-Functional Aspects, OWL, Ontology},
  url      = {http://www.jucs.org/jucs_20_3/generating_an_excerpt_of/jucs_20_03_0366_0384_rady.pdf},
}

@Article{Wynn2014,
  author   = {Wynn, Moe T and Low, Wei Zhe and ter Hofstede, Arthur HM and Nauta, Wiebe},
  title    = {A Framework for Cost-Aware Process Management: Cost Reporting and Cost Prediction},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {3},
  pages    = {406--430},
  month    = mar,
  abstract = {Organisations are constantly seeking efficiency gains for their business processes in terms of time and cost. Management accounting enables detailed cost reporting of business operations for decision making purposes, although significant effort is
required to gather accurate operational data. Process mining, on the other hand, may
provide valuable insight into processes through analysis of events recorded in logs by IT
systems, but its primary focus is not on cost implications. In this paper, a framework is
proposed which aims to exploit the strengths of both fields in order to better support
management decisions on cost control. This is achieved by automatically merging cost
data with historical data from event logs for the purposes of monitoring, predicting,
and reporting process-related costs. The on-demand generation of accurate, relevant
and timely cost reports, in a style akin to reports in the area of management accounting, will also be illustrated. This is achieved through extending the open-source process
mining framework ProM.},
  file     = {:done rp/22.pdf:PDF},
  keywords = {Business process management, management accounting, process mining, cost reporting, cost prediction.},
  url      = {http://www.jucs.org/jucs_20_3/a_framework_for_cost/jucs_20_03_0406_0430_wynn.pdf},
}

@Article{Matsumoto2014,
  author   = {Matsumoto, Patricia Megumi and Guerra, Eduardo},
  title    = {An Approach for Mapping Domain-Specific AOM Applications to a General Model},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {4},
  pages    = {534--560},
  month    = apr,
  abstract = {An Adaptive Object Model (AOM) is a common architectural style for systems in
which classes, attributes, relationships and behaviors of applications are represented as
metadata consumed at runtime. This allows them to be very flexible and changeable at runtime,
enabling their modification by end users without source code modification. Nevertheless, this
flexibility comes with a cost of a greater complexity when developing the system, and therefore
one usually uses a bottom-up approach, adding flexibility only when it is needed. As a
consequence, many AOM components are tied to the specific domain of a single application
and this fact makes it difficult to develop and use generic and reusable AOM frameworks that
properly handle specific requirements of the AOM architecture. This work presents an
architectural model that aims to adapt domain-specific AOM core structures to a common core
structure by identifying AOM roles played by each element through custom metadata
configuration. By doing this, this model allows the integration of domain-specific AOM
applications and AOM frameworks, making it feasible to develop reusable components for the
AOM architecture. This model is evaluated by creating an AOM framework and a case study
based on it, in which is performed a modularity and a performance analysis.},
  file     = {:done rp/23.pdf:PDF},
  keywords = {framework, metadata, modularity, architecture, adaptive system, decoupling, Adaptive Object Model. },
  url      = {http://jucs.org/jucs_20_4/an_approach_for_mapping/jucs_20_04_0534_0560_matsumoto.pdf},
}

@Article{IngirdChristense2014,
  author   = {Ingird Christense, Silvia Schiaffino},
  title    = {A Hybird Apporach for Group Profiling in Recommender Systems},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {4},
  pages    = {507--533},
  month    = apr,
  abstract = {Recommendation is a significant paradigm for information exploring, which focuses on the recovery of items of potential interest to users. Some activities tend to be social rather than individual, which puts forward the need to offer recommendations to groups of users. Group recommender systems present a whole set of new challenges within the field of recommender systems. In this paper, we present a hybrid approach based on group profiling for homogeneous and non-homogenous groups containing a few distant individual profiles among their members. This approach combines three familiar individual recommendation approaches: collaborative filtering, content-based filtering and demographic information. This hybrid approach allows the detection of those implicit similarities in the user rating profile, so as to include members with divergent profiles. We also describe the promising results obtained when evaluating the approach proposed in the movie and music domain.},
  file     = {:done rp/24.pdf:PDF},
  keywords = {Group Profiling, Group Recommender Systems, Aggregate Rating, Hybird recommender System, Group Hetrogenity},
  url      = {http://www.jucs.org/jucs_20_4/a_hybrid_approach_for},
}

@Article{Zouari2014,
  author   = {Mohamed Zouari, Cod´e Diop, Ernesto Exposito},
  title    = {Multilevel and Coordinated Self-management in Autonomic Systems based on Service Bus},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {3},
  pages    = {431--460},
  month    = mar,
  abstract = {Modern dynamic distributed systems require to dynamically take into account at runtime the changes in users’ needs and the execution environment variations in order to improve the quality of service. The evolution of distributed systems,
through the smart management of their properties and the extension of the existing integration infrastructures, becomes a necessity. Autonomic computing allows the
self-management of system properties at runtime, according to fluctuations in the environment and changes in users’ requirements. However, the mechanisms for parallel and
distributed execution of multiple self-management processes have not been addressed
substantially. It is critical to coordinate the execution of several processes performed
by different autonomic managers, while still guaranteeing specific and global goals
achievement. We address this issue by proposing a software architecture that allows
the coordination of multiple autonomic managers which handle several componentbased and service-oriented collaborative software entities. This architecture offers a
distributed cross-layer self-management solution through orchestration and choreography. Using both techniques, autonomic managers running on multiple locations and
different layers will be able to achieve their goals in a consistent and cost-effective way.
In this paper, we present a set of mechanisms intended to coordinate the distributed
execution of a set of self-management processes in one or more layers. We have chosen an use case involving the self-management of autonomic data replication systems
integrated via an autonomic service bus in order to illustrate our approach.},
  file     = {:done rp/25.pdf:PDF},
  keywords = {autonomic computing, quality of service, enterprise service bus, distributed and coordinated management},
  url      = {http://jucs.org/jucs_20_3/multilevel_and_coordinated_self/jucs_20_03_0431_0460_zouari.pdf},
}

@Article{Vleju2014,
  author   = {Vleju, Mircea Boris},
  title    = {Automatic Authentication to Cloud-Based Services.},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {3},
  pages    = {385--405},
  month    = mar,
  abstract = {: We describe the concept of automatic authentication for cloud-based services via the use of a client-centric solution for small and medium enterprises (SMEs).
In previous work we have introduced the Identity Management Machine (IdMM) which
is designed to handle the interaction between a client’s identity directory and various
cloud identity management systems. We now further refine this machine by describing
its interaction with various cloud authentication systems. The IdMM is designed to
aid SMEs in their adoption or migration to cloud-based services. The system allows
SMEs to store its confidential data on-premise, enhancing the client’s control over the
data. We further enhance the privacy related aspects of a client-to-cloud interaction via
the introduction of obfuscated and partially obfuscated identities which allow SMEs to
also choose the type of data being sent to a cloud service. Since the IdMM is a single
sign-on system capable of automatic authentication the risk of phishing or other social
engineering attacks is reduced as an individual user may not be aware of his or her
credentials for a given cloud service},
  file     = {:done rp/26.pdf:PDF},
  keywords = {: Abstract State Machine, Automatic Authentication, Client Centric, Cloud Computing, Identity Management, Small and Medium Enterprises},
  url      = {http://www.jucs.org/jucs_20_3/automatic_authentication_to_cloud/jucs_20_03_0385_0405_vleju.pdf},
}

@Article{Brodic2014,
  author   = {Darko Brodić, Carlos A. B. Mello, Čedomir A. Maluckov , Zoran N. Milivojević},
  title    = {An Approach to Skew Detection of Printed Documents},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {4},
  pages    = {488--506},
  month    = apr,
  abstract = {In this paper, we propose an approach to estimate the text skew for printed
documents. This is an important step to prevent errors in further stages of an automatic
document processing system (as text segmentation). Our approach is based on the statistical
analysis of the height of the connected components. In a nutshell, our algorithm is comprised of
four steps: (i) removal of redundant data; (ii) establishment of the connected components,
which represent filled convex hulls around each text element; (iii) enlargement of these
components using morphological erosion; (iv) removal of the largest connected component to
identify the first estimation of text skew. According to it, the connected components are
enlarged by oriented morphological erosion and the longest of them is extracted. Statistical
moments are applied to this longest component to evaluate its orientation and the global text
skew of the document is identified. At the end of this process, the original document is rotated
back based on the calculated angle. The performance of the proposed algorithm is examined by
testing on a custom dataset. The results support the robustness of our approach. },
  file     = {:done rp/27.pdf:PDF},
  keywords = { Document image analysis, Connected component analysis, Statistical analysis, Moment based method, Skew estimation },
  url      = {http://www.jucs.org/jucs_20_4/an_approach_to_skew/jucs_20_04_0488_0506_brodic.pdf},
}

@Article{Slootmaker2014,
  author   = {Slootmaker, Aad and Kurvers, Hub and Hummel, Hans GK and Koper, Rob},
  title    = {Developing Scenario-based Serious Games for Complex Cognitive Skills Acquisition: Design, Development and Evaluation of the EMERGO Platform},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {4},
  pages    = {561--582},
  month    = mar,
  abstract = { Serious games are considered to provide powerful and attractive ways to acquire
complex cognitive skills for education and training. But existing platforms for development of
game-based e-learning often appear either not to be very user-friendly or too rigid or costly.
This article addresses the design, development and evaluation of a generic platform for fast and
flexible development and delivery of a wide variety of scenario-based games that enables
complex cognitive skills acquisition. We present the requirements for the EMERGO platform
and which common components it offers to cater for most of the needed functionalities within
scenario-based games. We explain how users in various roles can use the platform to manage,
develop, deliver and play a broad variety of scenario-based games. Evaluation data are
presented to back up the claim that the platform indeed allows for faster, more user-friendly
and less costly development and delivery of scenario-based games. Seven years after the
platform has been launched, it until now has proven successful and still continues to evolve.
We close off with some conclusions and needs for further development. },
  file     = {:done rp/28.pdf:PDF},
  keywords = { Adaptive eLearning, eLearning Platforms, Technology Enhanced Learning, Game Based Learning},
  url      = {http://www.jucs.org/jucs_20_4/developing_scenario_based_serious/jucs_20_04_0561_0582_slootmaker.pdf},
}

@Article{Ajmal2014,
  author   = {Ajmal, Sana and Rasheed, Asim and Qayyum, Amir and Hasan, Aamir},
  title    = {Classification of VANET MAC, Routing and Approaches A Detailed Survey},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {4},
  pages    = {462--487},
  month    = apr,
  abstract = {: Human safety considerations linked with rapidly growing auto mobile market has
given special attention to the Intelligent Transportation System (ITS). ITS provides a set of standards for inter vehicular communication with emphasis on safety, traffic efficiency and infotainment related applications. In ITS, the vehicles acting as mobile nodes, form a specialized ad hoc
network, known as Vehicular Ad-hoc Network (VANET). Although, VANET and ITS are under
intense research since last decade, technology still lacks large scale deployment. Vehicle to Vehicle (V2V) and Vehicle to Infrastructure (V2I) communications are the main research goals of
ITS. High relative node velocity and high active node density has presented peculiar challenges
to connectivity within VANET. VANET connectivity and routing requirements range from the
time critical safety applications, to the time and space hovering, delay tolerant and infotainment
applications. This paper reviews connectivity issues in VANET with emphasis on routing, and
offers comprehensive literature review on state of the art in VANET routing, with its detailed
classifications. It also compares some standard architectures of VANET from MAC, routing and
management perspective, i.e., WAVE by IEEE, CALM by ISO, C2CNet by C2C consortium /
GeoNet.},
  file     = {:done rp/29.pdf:PDF},
  keywords = {Vehicular Ad hoc Networks, ITS, Routing Protocols, Routing Metrics},
  url      = {http://jucs.org/jucs_20_4/classification_of_vanet_mac/jucs_20_04_0462_0487_ajmal.pdf},
}

@Article{Maly2014,
  author   = {Jakub Malý and Martin Nečaský},
  title    = {Evaluation of OCL Expressions over XML Data Model},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {3},
  pages    = {329--365},
  month    = mar,
  abstract = {Complex applications can benefit greatly from using conceptual models and Model Driven Architecture during development, deployment and runtime. XML applications are not different. In this paper, we examine the possibility of using Object Constraint Language (OCL) for expressing constraints over a conceptual model for XML data. We go through the different classes of OCL expression and show how each class can be translated into XPath constructs. Subsequently we show how the constraints can be checked using Schematron. We introduce a function library OclX, which provides constructs necessary to translate those OCL constructs that have no counterpart in XPath. With our tool, it is possible to check validity of OCL constraints in XML data.},
  file     = {:done rp/30.pdf:PDF},
  keywords = { MDA, OCL, Schematron, XML, integrity constraints},
  url      = {http://www.jucs.org/jucs_20_3/evaluation_of_ocl_expressions},
}

@Article{Oliveira2014,
  author   = {Oliveira, Raphael Pereira de and Blanes, David and Gonzalez-Huerta, Javier and Insfran, Emilio and Abrah{\~a}o, Silvia and Cohen, Sholom and Almeida, Eduardo Santana de},
  title    = {Defining and Validating a Feature-Driven Requirements Engineering Approach},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {5},
  pages    = {666--691},
  month    = may,
  abstract = { The specification of requirements is a key activity for achieving the goals of any
software project and it has long been established and recognized by researchers and
practitioners. Within Software Product Lines (SPL), this activity is even more critical owing to
the need to deal with common, variable, and product-specific requirements, not only for a
single product but for the whole set of products. In this paper, we present a Feature-Driven
Requirements Engineering approach (FeDRE) that provides support to the requirements
specification of SPL. The approach realizes features into functional requirements by
considering the variability captured in a feature model. It also provides detailed guidelines on
how to associate chunks of features from a feature model and to consider them as the context
for the Use Case specification. The evaluation of the approach is illustrated in a case study for
developing an SPL of mobile applications for emergency notifications. This case study was
applied within 14 subjects, 8 subjects from Universitat Politècnica de València and 6 subjects
from Federal University of Bahia. Evaluations concerning the perceived ease of use, perceived
usefulness, effectiveness and efficiency as regards requirements analysts using the approach are
also presented. The results show that FeDRE was perceived as easy to learn and useful by the
participants.},
  file     = {:done rp/31.pdf:PDF},
  keywords = { Software Product Lines, Requirements Specification, Reuse},
  url      = {http://www.jucs.org/jucs_20_5/defining_and_validating_a/jucs_20_05_0666_0691_oliveira.pdf},
}

@Article{Fantinato2014,
  author  = {Fantinato, Marcelo and Oquendo, Flavio},
  title   = {Software Components, Architectures and Reuse: Software Product Line Engineering and Source Code Enhancements J.UCS Special Issue},
  journal = {J.UCS},
  year    = {2014},
  volume  = {20},
  number  = {5},
  pages   = {583--586},
  month   = may,
  file    = {:done rp/32.pdf:PDF},
  url     = {http://www.jucs.org/jucs_20_5/software_components_architectures_and/jucs_20_05_0583_0586_editorial.pdf},
}

@Article{Ferreira2014,
  author   = {Ferreira, Felype and Gheyi, Rohit and Borba, Paulo and Soares, Gustavo},
  title    = {A Toolset for Checking SPL Refinements},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {5},
  pages    = {587--614},
  month    = may,
  abstract = {Developers evolve software product lines (SPLs) manually or using typical
program refactoring tools. However, when evolving an SPL to introduce new features
or to improve its design, it is important to make sure that the behavior of existing products is not affected. Typical program refactorings cannot guarantee that because the
SPL context goes beyond code and other kinds of core assets, and involves additional
artifacts such as feature models and configuration knowledge. Besides that, we typically have to deal with a set of alternative assets that do not constitute a well-formed
program in an SPL. As a result, manual changes and existing program refactoring tools
may introduce behavioral changes or invalidate existing product configurations. To reduce such risks, we propose approaches and implement four tools for making product
line evolution safer. These tools check if SPL transformations preserve the behavior
of the original SPL products. They implement different and practical approximations
of refinement notions from a theory for safely evolving SPLs. Besides specifying the
algorithms of each approach, we compare them with respect to soundness, performance
and code coverage in 35 evolution scenarios of an SPL with 32 KLOC.},
  file     = {:done rp/33.pdf:PDF},
  keywords = {software product lines, safe evolution, refactoring, checking tools},
  url      = {http://www.jucs.org/jucs_20_5/a_toolset_for_checking/jucs_20_05_0587_0614_ferreira.pdf},
}

@Article{Accioly2014,
  author   = {Accioly, Paola RG and Borba, Paulo and Bonifacio, Rodrigo},
  title    = {Controlled Experiments Comparing Black-box Testing Strategies for Software Product Lines},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {5},
  pages    = {615--639},
  month    = may,
  abstract = {SPL testing has been considered a challenging task, mainly due to the
diversity of products that might be generated from an SPL. To deal with this problem,
techniques for specifying and deriving product specific functional test cases have been
proposed. However, there is little empirical evidence of the benefits and drawbacks of
these techniques. To provide this kind of evidence, in a previous work we conducted an
empirical study that compared two design techniques for black-box manual testing, a
generic technique that we have observed in an industrial test execution environment,
and a product specific technique whose functional test cases could be derived using
any SPL approach that considers variations in functional tests. Besides revisiting the
first study, here we present a second study that reinforce our findings and brings new
insights to our investigation. Both studies indicate that specific test cases improve test
execution productivity and quality.},
  file     = {:done rp/34.pdf:PDF},
  keywords = {Black-box Testing, Software Product Lines, Empirical Software Engineering},
  url      = {http://www.jucs.org/jucs_20_5/controlled_experiments_comparing_black/jucs_20_05_0615_0639_accioly.pdf},
}

@Article{Alferez2014,
  author   = {Mauricio Alférez, Roberto E. Lopez-Herrejón, Ana Moreira, Vasco Amaral, Alexander Egyed},
  title    = {Consistency Checking in Early Software Product Line Specifications - The VCC Approach},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {5},
  pages    = {640--665},
  month    = may,
  abstract = {Software Product Line Engineering (SPLE) is a successful paradigm to produce a family of products for a specific domain. A challenge in SPLE is to check that
different models used in early SPL specification do not contain inconsistent information
that may be propagated and generate inconsistent products that do not conform to its
requirements. This challenge is difficult to address due to the high number of possible
combinations of product features and model fragments specifying those features. Variability Consistency Checking (VCC) offers automatic means to address that challenge.
VCC relates information inferred from the relationships between features and from
base models related to those features. Validating if all the products in an SPL satisfy
user-defined consistency constraints is based on searching for a satisfying assignment
of each formula generated by VCC. We validated VCC and its supporting tool on two
case studies from different application domains, the results were encouraging as we did
not observed significant performance penalties.},
  file     = {:done rp/35.pdf:PDF},
  keywords = {Model-Driven Development, Variability Modeling, Verification, ModelBased Software Product Lines, Requirements Engineering, Architecture Design, Feature Modeling Analysis, Variability-Intensive Systems, Highly Configurable Systems.},
  url      = {http://jucs.org/jucs_20_5/consistency_checking_in_early/jucs_20_05_0640_0665_alferez.pdf},
}

@Article{Mello2014,
  author   = {de Mello, Rafael Maiani and Nogueira, Eld{\^a}nae and Schots, Marcelo and Werner, Cl{\'a}udia Maria Lima and Travassos, Guilherme Horta},
  title    = {Verification of Software Product Line Artefacts: A Checklist to Support Feature Model Inspections},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {5},
  pages    = {720--745},
  month    = may,
  abstract = {Software Product Line Engineering (SPL) should ensure the correctness,
completeness and consistency of its artefacts and related domain to prevent the propagation of
defects in derived products. Software inspection techniques are effective in detecting defects in
software artefacts and avoiding their propagation throughout the software development process.
However, the results of a quasi-systematic review of the technical literature reported in this
paper pointed to a lack of such techniques to support the inspection of SPL artefacts, including
techniques to support the inspection of feature models (FMs) that are largely used in domain
modelling. Therefore, a checklist-based inspection technique (FMCheck) has been developed to
support the detection of defects on FMs. FMCheck is configurable and can be applied to the
original feature model notation (the FODA approach) and its extensions, including the
Odyssey-FEX notation. The inspection technique was empirically evaluated, having indicated
its feasibility and effectiveness. It is possible to see that inspectors applying FMCheck to
inspect FMs can be more effective than those applying ad-hoc techniques, regarding four
distinct domains},
  file     = {:done rp/36.pdf:PDF},
  keywords = {Feature Model, Software Inspection, Domain Engineering, Software Reuse, Software Product Line, Experimental Software Engineering.},
  url      = {http://jucs.org/jucs_20_5/verification_of_software_product/jucs_20_05_0720_0745_mello.pdf},
}

@Article{Medeiros2014,
  author   = {Fl´avio Medeiros, M´arcio Ribeiro, Rohit Gheyi, Baldoino Fonseca},
  title    = {A Catalogue of Refactorings to Remove Incomplete Annotations},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {5},
  pages    = {Baldoino Fonseca},
  month    = may,
  abstract = {Developers use the C Preprocessor (CPP) to handle portability and variability in program families of different sizes and domains. However, despite the widely
use of the CPP in practice, it is often criticised due to its negative impact on code
quality and maintainability, tool development, and its error-prone characteristics. In
particular, developers aggravate these problems when using incomplete annotations,
i.e., directives encompassing only parts of syntactical units. In a previous work, we
performed an empirical study on 41 C program family releases and found that almost
90% of syntax errors occur in incomplete annotations. There are some refactorings to
remove incomplete annotations proposed in the literature. However, they clone code
and increase Lines of Code (LOC). To avoid incomplete annotations and their intrinsic
problems, in this article we propose a catalogue of refactorings that converts incomplete
annotations into complete ones without cloning code. We implement an Eclipse plug-in
to help developers applying our refactorings automatically. To evaluate our catalogue,
we performed a study to analyse questions related to code cloning, LOC, and number
of directives. To answer our research questions, we analyse releases of 12 C program
families of different domains ranging from 4.9 thousand to 1.5 million LOC. The results
show that our catalogue can remove all incomplete annotations without cloning code,
and increasing only in 0.04% the LOC and in 2.10% the number of directives.},
  file     = {:done rp/37.pdf:PDF},
  keywords = {: Refactoring, C Language, Preprocessors, Program Families},
  url      = {http://www.jucs.org/jucs_20_5/a_catalogue_of_refactorings/jucs_20_05_0746_0771_medeiros.pdf},
}

@Article{Lemos2014,
  author   = {Otavio A. L. Lemos, Adriano C. de Paula, Gustavo Konishi, Sushil Bajracharya, Joel Ossher, Cristina Lopes},
  title    = {Thesaurus-Based Tag Clouds for Test-Driven Code Search},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {5},
  pages    = {772--796},
  month    = may,
  abstract = {Test-driven code search (TDCS) is an approach to code search and reuse
that uses test cases as inputs to form the search query. Together with the test cases
that provide more semantics to the search task, keywords taken from class and method
names are still required. Therefore, the effectiveness of the approach also relies on how
good these keywords are, i.e., how frequently they are chosen by developers to name
the desired functions. To help users choose adequate words in their query test cases,
visual aids can be used. In this paper we propose thesaurus-based tag clouds to show
developers terms that are more frequently used in the code repository to improve their
search. Terms are generated by looking up words similar to the initial keywords on a
thesaurus. Tag clouds are then formed based on the frequency in which these terms
appear in the code base. Our approach was implemented with an English thesaurus
as an extension to CodeGenie, a Java- and Eclipse-based TDCS tool. Our evaluation
shows evidence that the approach can help improve the number of returned results,
recall (by ∼28%, on average), and precision (by ∼14%, on average). We also noticed
the visual aid can be especially useful for non-native speakers of the language in which
the code repository is written. These users are frequently unaware of the most common
terms used to name specific functionality in the code, in the given language.},
  file     = {:done rp/38.pdf:PDF},
  keywords = {Test-driven code search, code search, software reuse, tag clouds},
  url      = {http://www.jucs.org/jucs_20_5/thesaurus_based_tag_clouds/jucs_20_05_0772_0796_lemos.pdf},
}

@Article{SilvaJunior2014,
  author   = {Luiz Laerte Nunes da Silva Junior, Alexandre Plastino, Leonardo Gresta Paulino Murta},
  title    = {What Should I Code Now?},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {5},
  pages    = {797--821},
  month    = may,
  abstract = {In the software development field, the amount of data related to documentation and to the source code itself is huge. Relevant knowledge can be extracted
from these data, provided that the adequate tools are in place. In this context, data
mining can be seen as an important tool. This paper presents a new approach for
code completion based on sequential patterns mined from previous developed source
code. According to what is being coded, suggestions of new code sequences are made
based on the mined patterns. As a result, a plug-in for the Eclipse IDE, named Vertical
Code Completion, was developed and applied over widely known Open Source systems,
identifying that our approach could provide suggestions that would anticipate what a
developer intends to code.},
  file     = {:done rp/39.pdf:PDF},
  keywords = {Code Completion, Sequential Pattern Mining, Software Maintenance.},
  url      = {http://www.jucs.org/jucs_20_5/what_should_i_code},
}

@Article{Varajao2014,
  author  = {João Varajão and Ricardo Martinho and Pedro Soto Acosta},
  title   = {Enterprise Information Systems J.UCS Special Issue},
  journal = {J.UCS},
  year    = {2014},
  volume  = {20},
  number  = {6},
  pages   = {822--825},
  month   = jun,
  file    = {:done rp/40.pdf:PDF},
  url     = {http://www.jucs.org/jucs_20_6/enterprise_information_systems/abstract.html},
}

@Article{Huysegoms2014,
  author   = {Huysegoms, Tom and Snoeck, Monique and Dedene, Guido and Goderis, Antoon and Stumpe, Frank},
  title    = {Using and Extending Formal Concept Analysis to Visualise Variability during Requirements Engineering},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {6},
  pages    = {842--858},
  month    = jun,
  abstract = { Research on variability in software artefacts is something which is already studied
extensively in research. The visualisation of variability is one aspect of this research, and
results like e.g. feature diagrams are well-known and well-spread. When it concerns the origin
of the variability within the phase of requirements engineering, research is much scarcer. A
visualisation technique for both representing the origin and the amount of variability in
requirements is not readily available in research. This paper provides a way to represent the
origin of variability in requirements with the aid of a technique called formal concept analysis
(FCA). Additionally the support that FCA can provide for variability related decisions during
(early) requirements engineering is also depicted in this paper. Proof of the usability of FCA for
the visualization, and documentation, of variability is shown with the aid of a real-life case
study. FCA is also applied in the real-life case study to check the compatibility of FCA as a
visualization method to support variability decision making during requirements engineering. },
  file     = {:done rp/41.pdf:PDF},
  keywords = {: Requirements Management, Variability Management, Formal Concept Analysis, Harmonization, Variabilization},
  url      = {http://jucs.org/jucs_20_6/using_and_extending_formal/jucs_20_06_0842_0858_huysegoms.pdf},
}

@Article{Putnik2014,
  author   = {Goran D. Putnik and Maria Manuela Cruz-Cunha},
  title    = {A Taxonomy for Virtual Enterprises},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {6},
  pages    = {859--884},
  month    = jun,
  abstract = {The purpose of this paper is to present a taxonomy able to contribute to building a framework within the domain of Virtual Enterprises (VE), to facilitate the sharing of knowledge and contributions to knowledge, as well as for trust building among VE stakeholders. A VE taxonomy currently does not exist, and this lack is felt in the ambiguous way that some concepts are addressed, leading to a fragment understanding that hinders the development of the science of VE integration and management. The structure of the taxonomy developed is based on the view of the system as a 5-tuple consisting of Input, Control, Output, Mechanism, and Process, which is the underlying system-view in the well-know IDEF0 diagramming technique. In particular, this taxonomy addresses the VE extended lifecycle that implies the use of a meta-organization called Market of Resources, as an original contribution to the VE theory and practice. The taxonomy presented does not repeat what the literature already includes, or the commonplaces, and it is constructed in a way to be easily complemented with other VE partial taxonomies that may be found in literature. Some suggestions for extensions to other interrelated domains (as evolution leaves taxonomies in an open or incompleteness state) are given in the text.},
  file     = {:done rp/42.pdf:PDF},
  keywords = { Market of Resources, taxonomy, virtual enterprise},
  url      = {http://www.jucs.org/jucs_20_6/a_taxonomy_for_virtual/jucs_20_06_0859_0884_putnik.pdf},
}

@Article{Herranz2014,
  author   = {Eduardo Herranz and Ricardo Colomo-Palacios and Antonio de Amescua Seco and Murat Yilmaz},
  title    = {Gamification as a Disruptive Factor in Software Process Improvement Initiatives},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {6},
  pages    = {885--906},
  month    = jun,
  abstract = {For any Software Process Improvement (SPI) initiative to succeed human factors, in particular, motivation and commitment of the people involved should be kept in mind. In fact, Organizational Change Management (OCM) has been identified as an essential knowledge area for any SPI initiative. However, enough attention is still not given to the human factors and therefore, the high degree of failures in the SPI initiatives is directly linked to a lack of commitment and motivation. Gamification discipline allows us to define mechanisms that drive people's motivation and commitment towards the development of tasks in order to encourage and accelerate the acceptance of an SPI initiative. In this paper, a gamification framework oriented to both organization needs and software practitioners groups involved in an SPI initiative is defined. This framework tries to take advantage of the transverse nature of gamification in order to apply its Critical Success Factors (CSF) to the organizational change management of an SPI. Gamification framework guidelines have been validated by some qualitative methods. Results show some limitations that threaten the reliability of this validation. These require further empirical validation of a software organization},
  file     = {:done rp/43.pdf:PDF},
  keywords = {gamification, organizational change management, software process improvement},
  url      = {http://www.jucs.org/jucs_20_6/gamification_as_a_disruptive/jucs_20_06_0885_0906_herranz.pdf},
}

@Article{Mayeh2014,
  author   = {Maral Mayeh and Thurasamy Ramayah and Simona Popa},
  title    = {The Role of Absorptive Capacity in the Usage of a Complex Information System: The Case of the Enterprise Information System},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {6},
  pages    = {826--841},
  month    = jun,
  abstract = { The purpose of this study is to model the relationship between absorptive capacity and intention to use in the Enterprise Resource Planning (ERP) environment in Iran. This research is a correlation study where a field survey was employed for data collection. The unit of analysis is Iranian individuals who are ERP user in organizations using ERP systems. The questionnaires were sent to the selected organizations. Using a structural equation modeling analysis we tested the hypothesized relationship using AMOS version 16.0. The results indicate that all three absorptive capacity measures to be good predictors of intention to use. Absorptive capacity for applying was the strongest predictor followed by absorptive capacity for understanding and absorptive capacity for assimilating. When implementing complex information systems, managers must also look at the absorptive capacity of the users in order to successful implementation of the system and to ensure continued usage. Previous researchers have not looked at the role of absorptive capacity in system usage at the same rate as those related to technology acceptance research which only focuses on the ease of use and usefulness. Thus this research adds on to the existing literature where future researchers may want to expand on the factors that may influence absorptive capacity for further policy implications.},
  file     = {:done rp/44.pdf:PDF},
  keywords = {ERP, Iran, SEM, absorptive capacity for applying,, absorptive capacity for assimilating, absorptive capacity for understanding},
  url      = {http://www.jucs.org/jucs_20_6/the_role_of_absorptive/jucs_20_06_0826_0841_mayeh.pdf},
}

@Article{Andrade2014,
  author   = {Rodrigo Andrade and Henrique Rebelo and Marcio Ribeiro and Paulo Borba},
  title    = {Flexible Feature Binding with AspectJ-based Idioms},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {5},
  pages    = {692--719},
  month    = may,
  abstract = {: In Software Product Lines (SPL), we can bind reusable features to compose
a product at different times, which in general are static or dynamic. The former allows
customizability without any overhead at runtime. On the other hand, the latter allows
feature activation or deactivation while running the application with the cost of performance and memory consumption. To implement features, we might use aspect-oriented
programming (AOP), in which aspects enable a clear separation between invariable
code and variable code. In this context, recent work provides AspectJ-based idioms
to implement flexible feature binding. However, we identified some design deficiencies.
Thus, to solve the issues of these idioms, we incrementally create three AspectJ-based
idioms. We apply these idioms to provide flexible binding for 16 features from five
different product lines. Moreover, to evaluate our idioms, we quantitatively analyze
them with respect to code cloning, scattering, tangling, and size by means of software
metrics. Besides that, we qualitatively discuss our idioms in terms of code reusability,
changeability, instrumentation overhead, behavior, and feature interaction. In conclusion, we show evidences that our idioms address the issues of those existing ones.},
  file     = {:done rp/45.pdf:PDF},
  keywords = {: Software Product Lines, Aspect-Oriented Programming, Idioms, Flexible Feature Binding},
  url      = {http://www.jucs.org/jucs_20_5/flexible_feature_binding_with/jucs_20_05_0692_0719_andrade.pdf},
}

@Article{Cubo2014,
  author  = {Javier Cubo and Guadalupe Ortiz and Juan Boubeta-Puig and Howard Foster and Winfried Lamersdorf},
  title   = {Adaptive Services for the Future Internet J.UCS Special Issue},
  journal = {J.UCS},
  year    = {2014},
  volume  = {20},
  number  = {8},
  pages   = {1046--1048},
  month   = aug,
  file    = {:done rp/46.pdf:PDF},
  url     = {http://www.jucs.org/jucs_20_8/adaptive_services_for_the/jucs_20_08_1046_1048_editorial.pdf},
}

@Article{Rijo2014,
  author   = {Rui Rijo and Catarina Silva and Luis Pereira and Dulce Gonçalves and Margarida Agostinho},
  title    = {Decision Support System to Diagnosis and Classification of Epilepsy in Children},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {6},
  pages    = {907--923},
  month    = jun,
  abstract = { Clinical decision support systems play an important role in organizations. They have
a tight relation with the information systems. Our goal is to develop a system to support the
diagnosis and the classification of epilepsy in children. Around 50 million people in the world
have epilepsy. Epilepsy diagnosis can be an extremely complex process, demanding
considerable time and effort from physicians and healthcare infrastructures. Exams such as
electroencephalograms and magnetic resonances are often used to create a more accurate
diagnosis in a short amount of time. After the diagnosis process, physicians classify epilepsy
according to the International Classification of Diseases, ninth revision (ICD-9). Physicians
need to classify each specific type of epilepsy based on different data, e.g., types of seizures,
events and exams’ results. The classification process is time consuming and, in some cases,
demands for complementary exams. This work presents a text mining approach to support
medical decisions relating to epilepsy diagnosis and ICD-9-based classification in children. We
put forward a text mining approach using electronically processed medical records, and apply
the K-Nearest Neighbor technique as a white-box multiclass classifier approach to classify each
instance, mapping it to the corresponding ICD-9-based standard code. Results on real medical
records suggest that the proposed framework shows good performance and clear
interpretations, albeit the reduced volume of available training data. To overcome this hurdle,
in this work we also propose and explore ways of expanding the dataset. },
  file     = {:done rp/47.pdf:PDF},
  keywords = {epilepsy, diagnosis, clinical decision support systems, medical information systems, electronic medical records, ICD codes, data mining, text mining, machine learning },
  url      = {http://www.jucs.org/jucs_20_6/decision_support_system_to/jucs_20_06_0907_0923_rijo.pdf},
}

@Article{Cubo2014a,
  author   = {Antonio Brogi ,Javier Cubo, Laura González , Ernesto Pimentel, Raúl Ruggia},
  title    = {Dynamic Verification of Mashups of Service-Oriented Things through a Mediation Platform},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {7},
  pages    = {964--985},
  month    = aug,
  abstract = {The new Internet is evolving into the vision of the Internet of Things, where physical
world entities are integrated into virtual world things. Things are expected to become active
participants in business, information and social processes. Then, the Internet of Things could
benefit from the Web Service architecture like today’s Web does; so Future service-oriented
Internet things will offer their functionality via service-enabled interfaces. As demonstrated in
previous work, there is a need of considering the behaviour of things to develop applications in
a more rigorous way. We proposed a lightweight model for representing such behaviour based
on the service-oriented paradigm and extending the standard DPWS profile to specify the
(partial) order with which things can receive messages. To check whether a mashup of things
respects the behaviour, specified at design-time, of composed things, we proposed a static
verification. However, at run-time a thing may change its behaviour or receive requests from
instances of different mashups. Then, it is required to check and detect dynamically possible
invalid invocations provoked by the behaviour’s changes. In this work, we extend our static
verification with an approach based on mediation techniques and complex event processing to
detect and inhibit invalid invocations, checking that things only receive requests compatible
with their behaviour. The solution automatically generates the required elements to perform
run-time validation of invocations, and it may be extended to validate other issues. Here, we
have also dealt with quality of service and temporal restrictions. },
  file     = {:done rp/51.pdf:PDF},
  keywords = { Run-Time Verification, Composition, Mashup, Behaviour, Service-Oriented Things, Internet of Things, Web of Things, Complex Event Processing, Mediation Patterns },
  url      = {http://www.jucs.org/jucs_20_8/dynamic_verification_of_mashups},
}

@Article{Calvo2014,
  author   = {Rocío Calvo, Ana Iglesias, Lourdes Moreno},
  title    = {User-Centered Requirement Engineering for Accessible Chats in m-Learning},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {7},
  pages    = {964--985},
  month    = jul,
  abstract = { Chat applications are useful synchronous tools in mobile learning (m-learning)
environments. However, these tools have accessibility problems which cannot be avoided by
students and teachers with disabilities. This paper focuses on detecting these accessibility
problems. Specifically, this paper presents the Requirement Engineering (RE) process carried
out to obtain the requirements needed to improve the interaction for people who experience
problems with the Flow and Rhythm of the conversation in chats. A methodological approach
has been followed and Software Engineering (SE) and Human Computer Interaction (HCI)
disciplines were combined in order to improve the interaction during the chat.},
  file     = {:done rp/50.pdf:PDF},
  keywords = { Accessibility, mobile, chat, Human Computer Interaction, Software Engineering, Requirements Engineering},
  url      = {http://www.jucs.org/jucs_20_7/user_centered_requirement_engineering},
}

@Article{Berman2014,
  author   = {Berman, Benjamin and Hourcade, Juan Pablo},
  title    = {Keyboard-Card Menus: A New Presentation of Non-Standard Shortcuts},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {7},
  pages    = {986--1005},
  month    = jul,
  abstract = {“Keyboard-card menus” are a new type of menu system in which potentially hundreds of menu items are arranged in sets of keyboard patterns that are designed to be navigated using only a computer keyboard’s character keys, for fast access. In selecting items from these menus, novice users physically rehearse the same actions
that an expert would use. We describe these menus and their potential applications
in further detail, along with a study comparing keyboard-card menus’ presentation of
what are effectively shortcuts with a presentation of these same shortcuts that uses
dropdown menus. The data from our study shows that keyboard-card menus have
significant advantages over dropdown menus in making the transition to expert use
faster.},
  file     = {:done rp/52.pdf:PDF},
  keywords = {Keyboard shortcuts, accuracy, efficiency, visualization, learnability, computer chording},
  url      = {http://www.jucs.org/jucs_20_7/keyboard_card_menus_a},
}

@Article{Arellano2014,
  author   = {Diana Arellano and Cristina Manresa-Yee and Volker Helzle},
  title    = {Let me Listen to Poetry, Let me See Emotions},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {7},
  pages    = {1006--1025},
  month    = jul,
  abstract = {This paper presents the design, implementation and evaluation of the interactive installation The Muses of Poetry (MoP). In MoP the user interacts with a virtual character, who in turn recites poetry while manifesting the emotional content of the poem using visual cues (as facial expressions) and an affective voice. The novelty of MoP is that it combines real-time character animation, semantic analysis, natural voice interaction and poetry to create a unique and surprising experience for the user.},
  file     = {:done rp/53.pdf:PDF},
  keywords = { User experience, affective computing, human-computer interaction},
  url      = {http://www.jucs.org/jucs_20_7/let_me_listen_to},
}

@Article{Hog2014,
  author   = {Chiraz El Hog, Raoudha Ben Djemaa, Ikram Amous},
  title    = {A User-Aware Approach to Provide Adaptive Web Services},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {6},
  pages    = {944--963},
  month    = jul,
  abstract = {Web services are rapidly gaining acceptance as a fundamental technology in the web fields. They are becoming the cutting edge of communication between the different applications all over the web. Because of today's wide diversity of devices together with the variety of the user's preferences, context-aware web services are becoming a fundamental challenge that must be targeted. This issue is a part of the Human Computer Interaction (HCI) discipline and it aims at adapting the web service behavior according to the user's context such as his specific work environment, language, type of Internet connection, devices and preferences. Many solutions have been proposed in this area. Nevertheless, the adaptation was carried out only at the runtime and it partially covered the user's general context. In this paper, we introduce a new context-aware approach that provides adaptive web services. Our approach allows to express requirements by taking into account potential user's profile in addition to the functional one. While the latter ensures the description of the web service-functionalities, adaptation expresses the ability of a service to be self-adapted to runtime context changes. Our approach deals with adaptation from the very beginning of the modeling step of a web service. Furthermore, it upgrades description and publication usual methods in order to support profile specification},
  file     = {:done rp/54.pdf:PDF},
  keywords = {HCI, adaptation, uddi, uml, web service, wsdl},
  url      = {http://www.jucs.org/jucs_20_7/a_user_aware_approach},
}

@Article{Moya2014,
  author   = {Sergio Moya and Sergi Grau and Dani Tost},
  title    = {First-Person Locomotion in 3D Virtual Environments: a Usability Analysis},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {7},
  pages    = {1026--1045},
  month    = jul,
  abstract = { 3D Virtual Environments (VE) are becoming popular as a tool for cognitive, functional and psychological assessment. Navigation in these environments is recognized as one of the most difficult activities in 3D Virtual Environments (VE). Users unfamiliar to 3D games, specially elder persons, get puzzled when they try to virtually move an avatar through these environments. Their inability to navigate prevents them from concentrating in the task and even to finish it. In this paper, we analyze the influence of different factors in locomotion control. We investigate the impact of having the cursor fixed at the camera center or leaving it free inside the current view. We also analyze the influence of the pitch angle on the camera control. In addition, we have designed an automatic locomotion system that we compare to user-controlled locomotion. We describe a virtual scenario and a test task that we have implemented to evaluate these different methods with users of diverse profiles.},
  file     = {:done rp/55.pdf:PDF},
  keywords = { camera control, locomotion, navigation, usability, virtual worlds},
  url      = {http://www.jucs.org/jucs_20_7/first_person_locomotion_in},
}

@Article{Vega2014,
  author   = {Davide Vega, Roc Meseguer, Felix Freitag, Sergio F. Ochoa},
  title    = {Understanding Collaboration in Volunteer Computing Systems},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {13},
  pages    = {1738--1765},
  month    = nov,
  abstract = {Volunteer computing is a paradigm in which devices participating in a distributed
environment share part of their resources to help others perform their activities. The
effectiveness of this computing paradigm depends on the collaboration attitude adopted by the
participating devices. Unfortunately for software designers it is not clear how to contribute with
local resources to the shared environment without compromising resources that could then be
required by the contributors. Therefore, many designers adopt a conservative position when
defining the collaboration strategy to be embedded in volunteer computing applications. This
position produces an underutilization of the devices’ local resources and reduces the
effectiveness of these solutions. This article presents a study that helps designers understand the
impact of adopting a particular collaboration attitude to contribute with local resources to the
distributed shared environment. The study considers five collaboration strategies, which are
analyzed in computing environments with both, abundance and scarcity of resources. The
obtained results indicate that collaboration strategies based on effort-based incentives work
better than those using contribution-based incentives. These results also show that the use of
effort-based incentives does not jeopardize the availability of local resources for the local
needs. },
  file     = {:done rp/56.pdf:PDF},
  keywords = {Volunteer Computing, Collaboration Strategy, Software Design, Effort-Based Incentives, Resource Sharing. },
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=Understanding+Collaboration+in+Volunteer+Computing+Systems&btnG=},
}

@Article{Lino2014,
  author   = {Natasha Lino, Clauirton Siebra, Austin Tate},
  title    = {Semantic Based Support for Planning Information Delivery in Human-agent Collaborative Teams},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {13},
  pages    = {1766--1790},
  month    = nov,
  abstract = {Collaborative teams are organizations where joint members work together to solve
mutual goals. Mixed-initiative planning systems are useful tools in such situations, because
they can support several common activities performed in these organizations. However, as
collaborative members are involved in different decision making planning levels, they
consequently require different information types and forms of receiving planning information.
Unfortunately, collaborative planning delivery is a subject that has not been given much
attention by researchers, so that users cannot make the most of such systems since they do not
have appropriate support for interaction with them. This work presents a general framework for
planning information delivery, which is divided into two main parts: a knowledge
representation aspect based on an ontological set and a reasoning mechanism for multimodality
visualization. This framework is built on a mixed-initiative planning basis, which considers the
additional requirements that the human presence brings to the development of collaborative
support systems. },
  file     = {:done rp/57.pdf:PDF},
  keywords = { Intelligent Planning, Ontology Design, Multiagent Systems },
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=Semantic+Based+Support+for+Planning+Information+Delivery+in+Human-agent+Collaborative+Teams&btnG=},
}

@Article{Zheng2014,
  author   = {Cheng Zheng, Weiming Shen, Hamada Ghenniwa},
  title    = {An Adaptive Intent Resolving Scheme for Service Discovery and Integration},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {13},
  pages    = {1791--1812},
  month    = nov,
  abstract = {Service discovery and integration is an important research area with efforts invested
to explore the potential advantages of collaborative computing in general and service-oriented
computing in particular. However, current technologies still limit their application within the
reach of enterprise systems or privately available services. Intents is an emerging and
innovative technique aimed to discover and integrate publically available services. In Intents,
intent message resolving is a critical step which is deemed to decide the quality of the whole
system. However, existing schemes applied in intent resolving adopt the exact-matching
strategy which may rule out services desired by the user. This paper brings in information
retrieval techniques and applies them to intent resolving. We take an empirical approach
through extensive experiments and analyses on a real dataset to obtain guiding principles.
Based on the resulting principles, an adaptive intent resolving scheme is designed. Afterwards,
we integrate the scheme into the Intents user agent developed in a previous project. },
  file     = {:done rp/58.pdf:PDF},
  keywords = { Service Discovery and Integration, Web Services, Intents, Intent Resolving },
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=An+Adaptive+Intent+Resolving+Scheme+for+Service+Discovery+and+Integration&btnG=},
}

@Article{Lopez-Gil2014,
  author   = {Juan-Miguel López-Gil, Rosa Gil, Roberto García , Cesar A. Collazos},
  title    = {EmotionsOnto: an Ontology for Developing Affective Applicationsc},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {13},
  pages    = {1813--1828},
  month    = nov,
  abstract = {EmotionsOnto is a generic ontology for describing emotions and their detection and
expression systems taking contextual and multimodal elements into account. The ontology is
proposed as a way to develop an easily computerizable and flexible formal model. Moreover, it
is based on the Web Ontology Language (OWL) standard, which also makes ontologies easily
shareable and extensible. Once formalized as an ontology, the knowledge about emotions can
be used in order to make computers more personalised and adapted to users’ needs. The
ontology has been validated and evaluated by means of an applications based on a emotionsaware Tangible User Interface (TUI). The TUI is guided by emotion knowledge previously
gathered using the same TUI and modelled using EmotionsOnto. },
  file     = {:done rp/59.pdf:PDF},
  keywords = {Design of affective interaction systems, emotions, ontologies, context, multimodality },
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=EmotionsOnto%3A+an+Ontology+for+Developing+Affective+Applications&btnG=},
}

@Article{Fu2014,
  author   = {Xiuwen Fu, Wenfeng Li , Giancarlo Fortino, Pasquale Pace , Gianluca Aloi , Wilma Russo},
  title    = {A Utility-Oriented Routing Scheme for Interest-Driven Community-Based Opportunistic Networks},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {13},
  pages    = {1829--1854},
  month    = nov,
  abstract = {Opportunistic networks, as representative networks evolved from social networks
and Ad-hoc networks, have been on cutting edges in recent years. Many research efforts have
focused on realistic mobility models and cost-effective routing schemes. The concept of
“community”, as one of the most inherent attributes of opportunistic networks, has been proved
to be very helpful in simulating mobility traces of human society and selecting suitable
message forwarders. This paper proposes an interest-driven community-based mobility model
by considering location preference and time variance in human behavior patterns. Based on this
enhanced mobility model, a novel two-layer routing algorithm, named InterCom, is presented
by jointly considering utilities generated by users’ activity degree and social relationships. The
results, obtained throughout an intensive simulation analysis, show that the proposed routing
scheme is able to improve delivery ratio while keeping the routing overhead and transmission
delay within a reasonable range with respect to well-known routing schemes for opportunistic
networks. },
  file     = {:done rp/60.pdf:PDF},
  keywords = {Opportunistic Networks, Mobility Model, Routing Algorithm, Community, Simulation Analysis, Performance Evaluation },
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=A+Utility-Oriented+Routing+Scheme+for+Interest-Driven+Community-Based+Opportunistic+Networks&btnG=},
}

@Article{Perera2014,
  author   = {Indika Perera, Dulani Meedeniya, Colin Allison, Alan Miller},
  title    = {User Support for Managed Immersive Education: An Evaluation of in-World Training for OpenSim},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {12},
  pages    = {1690--1707},
  month    = nov,
  abstract = {Supporting users for a competent interaction with 3 dimensional virtual worlds can
increase their user experience within the immersive education environment. User manuals and
other guide documents are popular supporting instruments for training new users of a software
system. Quite often these documents have many screenshots of the application user interface
which are used to steer a new user through sequential orders of actions. However, for complex
scenarios of user interactions, such as those found in virtual worlds, these types of documents
can become unhelpfully lengthy and unintuitive. The first part of this research was a
comparative analysis of traditional document-based user support with an in-world approach; a
prototype training island was developed in OpenSim and evaluated for its training support
against the OpenSim user guide documents. The results suggested in-world training can be a
better option of training for OpenSim than training documents. Second part of this research was
to evaluate a completed training environment, which consist of two OpenSim islands, one for
basic user training and one for training advanced OpenSim management. The results suggested
that training for advanced OpenSim management, which is not covered in user guide
documents, make users competent for managing their immersive environment. The final part of
the research, a case study, examined the effective use of this complete training environment for
module teaching and learner support. The results suggest that for learning the skills essential for
productive use of OpenSim-based educational environments, an in-world approach covering
advanced management functions of OpenSim is likely to be a better option than traditional user
manuals for the future needs for immersive education as a mainstream practice. },
  file     = {:done rp/61.pdf:PDF},
  keywords = { OpenSim, User Training, Virtual Worlds, Immersive Education, In-world Training},
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=User+Support+for+Managed+Immersive+Education%3A+An+Evaluation+of+in-World+Training+for+OpenSim&btnG=},
}

@Article{Pellas2014,
  author   = {Nikolaos Pellas},
  title    = {Exploring Interrelationships among High School Students’ Engagement Factors in Introductory Programming Courses via a 3D Multi-user Serious Game Created in Open Sim},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {12},
  pages    = {1608--1628},
  month    = nov,
  abstract = {The technological affordances of three-dimensional (3D) multi-user virtual worlds
and their effectiveness in task-based learning approaches are to a large extent well-established
in the international field of computer literacy research. However, less attention was given to
their positive or negative impact on student engagement. The current study seeks to investigate
the interrelationships of students’ engagement among multidimensional constructs consisting of
cognitive, emotional and behavioral factors in order to understand better the educational
community the learning effectiveness emerged through a 3D computer-supported and multiuser serious game created for introductory programming courses. An instructional design
framework based on Papert’s theory of Constructionism to be amplified the students’ activities
and management of their interactions in a 3D multi-user serious game created via an Open Sim
standalone server integrated with Scratch4OS is also proposed. Fifty-five (n=55) voluntary
students from three different high schools participated and experienced in a 3D mind-trap
puzzle game named Co.Co.I.A. (Collaborative Construction of Interactive Artifacts) to learn
basic programming structures. The empirical study findings indicated that student behavioral
engagement (attention, retention and energy expenditure for activity completion) had not only a
linear correlation with cognitive engagement (learning strategies for the construction of the
knowledge domain), but it had also a positive association with emotional engagement
(students’ positive emotions and achievement orientation) in collaborative learning tasks,
causing the reinforcement of the other two factors as well. },
  file     = {:done rp/62.pdf:PDF},
  keywords = { Programming courses, Open Sim, Scratch4OS, Serious games, Student engagement },
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=Exploring+Interrelationships+among+High+School+Students’+Engagement+Factors+in+Introductory+Programming+Courses+via+a+3D+Multi-user+Serious+Game+Created+in+Open+Sim&btnG=},
}

@Article{CarmenFernandezPanadero2014,
  author   = {Carmen Fernández Panadero, Valentín de la Cruz Barquero Carlos Delgado Kloos},
  title    = {PhyMEL-WS: Physically Experiencing the Virtual World. Insights into Mixed Reality and Flow State on Board a Wheelchair Simulator},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {12},
  pages    = {1629--1648},
  month    = nov,
  abstract = {Psychology has widely probed the relationship between body, mind and emotions,
these findings have been traditionally applied to physical learning but its penetration into the
academic environment was still slower than expected. Virtual worlds, augmented reality and
gamification applied to learning experiences, have once again highlighted the correlation
between the emotional state of the student and his learning outcomes. There have been many
studies around the concept of flow proposed by Csíkszentmihályi in 1988, what factors
influence their extent and how to promote it. Although the proposed model is widely accepted
by the scientific community there are some studies showing discrepancies between theoretical
models and experimental results. The scientific community demands more studies on how to
measure flow and how to analyse the factors behind these discrepancies. This paper presents a
study with 20 students between 21 and 36 years using a wheelchair simulator to reach
awareness about the difficulties that people with disabilities face daily. Experience confirms the
discrepancies between emotions calculated from the model and expressed directly by students.
Two of the main findings of this study are: (1) the influence of gender on emotions and (2)
some of the factors that moderate the theoretical measures to fit empirical values are related to
the four defining traits of a game proposed by McGonigal (challenging goals, clear rules, real
time feedback and voluntary participation). },
  file     = {:done rp/63.pdf:PDF},
  keywords = {Accessibility, Simulation, Wheelchair, Virtual Worlds, disability, social awareness, learning, 3DOF, Unity3D, flow state },
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=PhyMEL-WS%3A+Physically+Experiencing+the+Virtual+World.+Insights+into+Mixed+Reality+and+Flow+State+on+Board+a+Wheelchair+Simulator&btnG=},
}

@Article{Barbosa2014,
  author   = {Jorge Luis Victória Barbosa, Débora Nice Ferrari Barbosa, Jezer Machado de Oliveira, Solon Andrade Rabello Junior},
  title    = {A Decentralized Infrastructure for Ubiquitous Learning Environments},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {21},
  pages    = {1649--1669},
  month    = nov,
  abstract = {This article proposes a decentralized infrastructure for ubiquitous learning
environments called Global. The two main contributions of Global are its decentralized strategy
and its extensible architecture based on software agents. Global can be specialized to create
ubiquitous learning environments through the extension of its agents or through the addition of
new agents. The article presents the infrastructure architecture, describing the agents and
auxiliary components. Moreover, the article approaches the implementation and evaluation of
Global through two applications dedicated to education. The evaluation showed that the
infrastructure could be used for the development of decentralized learning systems, supporting
specifically the characteristics considered as strategic for ubiquitous learning. },
  file     = {:done rp/64.pdf:PDF},
  keywords = {Decentralization, Ubiquitous Computing, Ubiquitous Learning },
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=A+Decentralized+Infrastructure+for+Ubiquitous+Learning+Environments&btnG=},
}

@Article{Munoz-Cristobal2014,
  author   = {Juan A. Muñoz-Cristóbal, Alejandra Martínez-Monés, Juan I. Asensio-Pérez, Sara L. Villagrá-Sobrino, Javier E. Hoyos-Torío, Yannis Dimitriadis},
  title    = {City Ads: Embedding Virtual Worlds and Augmented Reality in Everyday Educational Practice},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {12},
  pages    = {1670--1689},
  month    = nov,
  abstract = {The use of immersive environments such as 3D virtual worlds (3DVWs) and
augmented reality (AR) in education has been profusely explored during the last decades,
showing significant evidence of its benefits for learning. However, the attempts to integrate
immersive environments in everyday educational practice are hampered by the difficulties that
these environments pose to teachers willing to set them up within the already demanding
ecology of technological resources present in the classroom. GLUEPS-AR is a system aimed to
help teachers deploy and enact learning designs that make use of web technologies (Virtual
Learning Environments and Web 2.0 tools), as well as immersive environments such as virtual
globes (e.g. Google Earth) used as 3DVW, and general-purpose mobile AR apps. This paper
presents the evaluation of the support provided by GLUEPS-AR for teachers that want to
appropriate immersive environments in their everyday practice with an affordable orchestration
effort. The evaluation followed an interpretive research perspective, and it was carried out in
the context of an authentic learning situation about advertising, conducted at a university
undergraduate course for pre-service teachers. The results of the evaluation showed that
GLUEPS-AR effectively supported the teacher in seamlessly embedding 3DVWs and AR in
her practice},
  file     = {:done rp/65.pdf:PDF},
  keywords = {Virtual world, Augmented reality, Immersion, Ubiquitous learning, Seamless learning},
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=City+Ads%3A+Embedding+Virtual+Worlds+and+Augmented+Reality+in+Everyday+Educational+Practice&btnG=},
}

@Article{Shen2014,
  author  = {Shen, Weiming and Li, Weidong and Pino, Jose Alberto and Luo, Junzhou},
  title   = {Collaborative Computing and Applications J.UCS Special Issue},
  journal = {J.UCS},
  year    = {2014},
  volume  = {20},
  number  = {13},
  pages   = {1798--1711},
  month   = nov,
  file    = {:done rp/66.pdf:PDF},
  url     = {http://www.jucs.org/jucs_20_13/collaborative_computing_and_applications/jucs_20_13_1708_1711_editorial.pdf},
}

@Article{Baloian2014,
  author   = {Baloian, Nelson and Aguirre, Diego and Zurita, Gustavo},
  title    = {Developing Distributed Collaborative Applications with HTML5 under the Coupled Objects Paradigm},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {13},
  pages    = {1712--1737},
  month    = nov,
  abstract = {One of the main tasks in developing distributed collaborative systems is to support
synchronization processes. The Coupled Objects paradigm has emerged as a way to easily
support these processes by dynamically coupling arbitrary user interface objects between
heterogeneous applications. In this article we present an architecture for developing distributed
collaborative applications using HTML5 and show its usage through the design and
implementation of a series of collaborative systems in different scenarios. The experience of
developing and using this architecture has shown that it is easy to use, robust and has good
performance. },
  file     = {:done rp/67.pdf:PDF},
  keywords = {Coupled objects paradigm; synchronization; HTML5; mobile collaboration; distributed collaborative systems},
  url      = {http://www.jucs.org/jucs_20_13/developing_distributed_collaborative_applications/jucs_20_13_1712_1737_baloian.pdf},
}

@Article{Yang2014,
  author   = {Yang, Ming and Liu, Bo and Wang, Wei and Luo, Junzhou and Shen, Xiaojun},
  title    = {Maximum Capacity Overlapping Channel Assignment Based on Max-Cut in 802.11 Wireless Mesh Networks},
  journal  = {J.UCS},
  year     = {2014},
  volume   = {20},
  number   = {13},
  pages    = {1855--1874},
  month    = nov,
  abstract = { By exploiting multi-radio multi-channel technology, wireless mesh networks can
effectively provide wireless broadband access to the Internet for mobile users. Due to the
limited number of orthogonal channels, overlapping channel assignment is one of the main
factors that greatly affect the network capacity. However, current results in this area are not so
satisfying. In this paper, we first propose a model for measuring achieved network capacity in
MR-WMNs. Then we prove that finding an optimal overlapping channel assignment in a given
MR-WMN with odd number of channels, is equivalent to finding an optimal assignment by
only using its orthogonal channels. This theory allows us to use fewer channels to solve
complicated channel assignment problems. Third, we prove that in 802.11b/g MR-WMN the
simplified optimization problem is a Max-3-Cut problem. Although this problem is NP-hard, it
has an efficient approximation algorithm that achieves approximation ratio of 1.19616
probabilistically by using the algorithm for Max-Cut whose approximation ratio is 1.1383
probabilistically. Based on the algorithm for Max-Cut, this paper proposes Max-Cut based
channel assignment (MCCA) which uses a heuristic method to adjust the result produced by the
Max-Cut algorithm to achieve an even better result. Finally, we perform extensive simulations
to compare the MCCA with a state-of-the-art Tabu-Search based algorithm. The results show
that the Max-Cut based overlapping channel assignment algorithm effectively and efficiently
improves on the network capacity compared with existing algorithms. },
  file     = {:done rp/68.pdf:PDF},
  keywords = { multi-radio multi-channel wireless mesh network; overlapping channel assignment; capacity optimization; graph coloring; Max-Cut },
  url      = {https://scholar.google.com.pk/scholar?hl=en&as_sdt=0%2C5&q=Maximum+Capacity+Overlapping+Channel+Assignment+Based+on+Max-Cut+in+802.11+Wireless+Mesh+Networks&btnG=},
}

@Comment{jabref-meta: databaseType:bibtex;}
